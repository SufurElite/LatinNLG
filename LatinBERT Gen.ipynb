{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271073d4",
   "metadata": {},
   "source": [
    "# LatinBERT Gen\n",
    "This approach will follow similarly to bert-babble as generated in the paper \"Bert has a voice let it speak, BERT as an RMF\" by X and Y at Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9984f67b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T16:40:45.323922Z",
     "iopub.status.busy": "2023-03-26T16:40:45.323654Z",
     "iopub.status.idle": "2023-03-26T16:40:45.330304Z",
     "shell.execute_reply": "2023-03-26T16:40:45.329562Z",
     "shell.execute_reply.started": "2023-03-26T16:40:45.323905Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, re\n",
    "from Data import dataExp\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import LatinBERT\n",
    "from LatinBERT.gen_berts import LatinBERT\n",
    "from LatinBERT.LatinTok import LatinTokenizer\n",
    "from LatinBERT.predict_words import predict, infilling\n",
    "from transformers import BertModel, BertForMaskedLM, BertPreTrainedModel\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "    from cltk.tokenizers.lat.lat import LatinWordTokenizer as WordTokenizer\n",
    "    from cltk.tokenizers.lat.lat import LatinPunktSentenceTokenizer as SentenceTokenizer\n",
    "from cltk.embeddings.embeddings import Word2VecEmbeddings as W2VE\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff58d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T16:40:04.714608Z",
     "iopub.status.busy": "2023-03-26T16:40:04.713684Z",
     "iopub.status.idle": "2023-03-26T16:40:07.106415Z",
     "shell.execute_reply": "2023-03-26T16:40:07.105890Z",
     "shell.execute_reply.started": "2023-03-26T16:40:04.714582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the existing corpus\n",
      "abbofloracensis had 1 pieces of work with a total of 5403 characters of text\n",
      "abelard had 1 pieces of work with a total of 13784 characters of text\n",
      "acticussincerius had 1 pieces of work with a total of 340 characters of text\n",
      "addison had 1 pieces of work with a total of 296 characters of text\n",
      "adso had 1 pieces of work with a total of 2351 characters of text\n",
      "aelredus had 1 pieces of work with a total of 20901 characters of text\n",
      "agnes had 1 pieces of work with a total of 11811 characters of text\n",
      "alanus had 1 pieces of work with a total of 34012 characters of text\n",
      "albericodamarcellise had 1 pieces of work with a total of 27 characters of text\n",
      "albertanus had 1 pieces of work with a total of 2869 characters of text\n",
      "albertofaix had 1 pieces of work with a total of 14123 characters of text\n",
      "alcuin had 1 pieces of work with a total of 487 characters of text\n",
      "aleandrogerolamo had 1 pieces of work with a total of 654 characters of text\n",
      "alfonsi had 1 pieces of work with a total of 17894 characters of text\n",
      "ambrose had 1 pieces of work with a total of 1246 characters of text\n",
      "ammianus had 18 pieces of work with a total of 152277 characters of text\n",
      "ampelius had 1 pieces of work with a total of 8667 characters of text\n",
      "andecavis had 1 pieces of work with a total of 161 characters of text\n",
      "andreasbergoma had 1 pieces of work with a total of 4834 characters of text\n",
      "andronicus had 1 pieces of work with a total of 557 characters of text\n",
      "angeloambrogini had 1 pieces of work with a total of 458 characters of text\n",
      "angelopoliziano had 1 pieces of work with a total of 469 characters of text\n",
      "angilbert had 1 pieces of work with a total of 382 characters of text\n",
      "annalesregnifrancorum had 1 pieces of work with a total of 25076 characters of text\n",
      "annalesvedastini had 1 pieces of work with a total of 8907 characters of text\n",
      "anon had 1 pieces of work with a total of 8621 characters of text\n",
      "anonymous had 1 pieces of work with a total of 1039 characters of text\n",
      "anselmepistula had 1 pieces of work with a total of 811 characters of text\n",
      "anselmproslogion had 1 pieces of work with a total of 7910 characters of text\n",
      "apicius had 1 pieces of work with a total of 1654 characters of text\n",
      "appverg had 1 pieces of work with a total of 12 characters of text\n",
      "appvergcomp had 1 pieces of work with a total of 18951 characters of text\n",
      "appvergculex had 1 pieces of work with a total of 3123 characters of text\n",
      "apuleius had 13 pieces of work with a total of 96788 characters of text\n",
      "aquinas had 1 pieces of work with a total of 1126 characters of text\n",
      "arbroath had 1 pieces of work with a total of 1194 characters of text\n",
      "archpoet had 1 pieces of work with a total of 5323 characters of text\n",
      "aristotle had 1 pieces of work with a total of 1952 characters of text\n",
      "arnobius had 1 pieces of work with a total of 6772 characters of text\n",
      "arnulf had 1 pieces of work with a total of 236 characters of text\n",
      "asconius had 1 pieces of work with a total of 19216 characters of text\n",
      "asserius had 1 pieces of work with a total of 14621 characters of text\n",
      "augustine had 7 pieces of work with a total of 69080 characters of text\n",
      "aureliusvictor had 2 pieces of work with a total of 23206 characters of text\n",
      "aus had 1 pieces of work with a total of 428 characters of text\n",
      "ausonius had 24 pieces of work with a total of 51304 characters of text\n",
      "ave had 1 pieces of work with a total of 1136 characters of text\n",
      "avianus had 1 pieces of work with a total of 5264 characters of text\n",
      "avienus had 1 pieces of work with a total of 4552 characters of text\n",
      "axio had 1 pieces of work with a total of 2845 characters of text\n",
      "bacon had 1 pieces of work with a total of 7934 characters of text\n",
      "balbus had 1 pieces of work with a total of 2662 characters of text\n",
      "balde had 1 pieces of work with a total of 127 characters of text\n",
      "baldo had 1 pieces of work with a total of 11374 characters of text\n",
      "bebel had 1 pieces of work with a total of 22436 characters of text\n",
      "bede had 5 pieces of work with a total of 95877 characters of text\n",
      "benedict had 1 pieces of work with a total of 15529 characters of text\n",
      "berengar had 1 pieces of work with a total of 6440 characters of text\n",
      "bernardcluny had 1 pieces of work with a total of 9267 characters of text\n",
      "bible had 1 pieces of work with a total of 1902 characters of text\n",
      "biggs had 1 pieces of work with a total of 7315 characters of text\n",
      "bill had 1 pieces of work with a total of 540 characters of text\n",
      "blesensis had 1 pieces of work with a total of 9500 characters of text\n",
      "boethius had 10 pieces of work with a total of 43252 characters of text\n",
      "boethiusdacia had 1 pieces of work with a total of 9053 characters of text\n",
      "bonaventura had 1 pieces of work with a total of 12067 characters of text\n",
      "boskovic had 1 pieces of work with a total of 5088 characters of text\n",
      "brevechronicon had 1 pieces of work with a total of 1427 characters of text\n",
      "buchanan had 1 pieces of work with a total of 6163 characters of text\n",
      "bultelius had 1 pieces of work with a total of 5655 characters of text\n",
      "caeciliusbalbus had 1 pieces of work with a total of 8511 characters of text\n",
      "caesar had 11 pieces of work with a total of 96121 characters of text\n",
      "caesaraugustus had 1 pieces of work with a total of 2930 characters of text\n",
      "calpurniusflaccus had 1 pieces of work with a total of 8733 characters of text\n",
      "calpurniussiculus had 1 pieces of work with a total of 6110 characters of text\n",
      "campion had 1 pieces of work with a total of 3287 characters of text\n",
      "capellanus had 1 pieces of work with a total of 38711 characters of text\n",
      "carm had 1 pieces of work with a total of 300 characters of text\n",
      "carmenarvale had 1 pieces of work with a total of 97 characters of text\n",
      "carmeninvictoriam had 1 pieces of work with a total of 2342 characters of text\n",
      "carmensaliare had 1 pieces of work with a total of 57 characters of text\n",
      "cassiodorus had 1 pieces of work with a total of 10326 characters of text\n",
      "catalogueliberien had 1 pieces of work with a total of 1541 characters of text\n",
      "cato had 1 pieces of work with a total of 2762 characters of text\n",
      "catullus had 1 pieces of work with a total of 15439 characters of text\n",
      "celsus had 8 pieces of work with a total of 125627 characters of text\n",
      "celtis had 1 pieces of work with a total of 286 characters of text\n",
      "censorinus had 1 pieces of work with a total of 12234 characters of text\n",
      "cicero had 122 pieces of work with a total of 1303304 characters of text\n",
      "cinna had 1 pieces of work with a total of 134 characters of text\n",
      "claud had 1 pieces of work with a total of 911 characters of text\n",
      "claudian had 19 pieces of work with a total of 71409 characters of text\n",
      "clitophon had 1 pieces of work with a total of 1796 characters of text\n",
      "colman had 1 pieces of work with a total of 289 characters of text\n",
      "columba had 1 pieces of work with a total of 6402 characters of text\n",
      "columbus had 1 pieces of work with a total of 2703 characters of text\n",
      "columella had 9 pieces of work with a total of 92306 characters of text\n",
      "comes had 1 pieces of work with a total of 86 characters of text\n",
      "commodianus had 1 pieces of work with a total of 189 characters of text\n",
      "corippus had 8 pieces of work with a total of 38301 characters of text\n",
      "corneliopaoloamalteo had 1 pieces of work with a total of 98 characters of text\n",
      "corvinus had 1 pieces of work with a total of 793 characters of text\n",
      "cotta had 1 pieces of work with a total of 2364 characters of text\n",
      "creeds had 1 pieces of work with a total of 1114 characters of text\n",
      "curtius had 1 pieces of work with a total of 11655 characters of text\n",
      "curtiusrufus had 8 pieces of work with a total of 89377 characters of text\n",
      "dante had 1 pieces of work with a total of 7043 characters of text\n",
      "dantealighieri had 1 pieces of work with a total of 21 characters of text\n",
      "dares had 1 pieces of work with a total of 9495 characters of text\n",
      "debury had 1 pieces of work with a total of 17429 characters of text\n",
      "declaratio had 1 pieces of work with a total of 1609 characters of text\n",
      "decretum had 1 pieces of work with a total of 2288 characters of text\n",
      "descartes had 1 pieces of work with a total of 2922 characters of text\n",
      "dicquid had 1 pieces of work with a total of 64 characters of text\n",
      "diesirae had 1 pieces of work with a total of 275 characters of text\n",
      "diravi had 1 pieces of work with a total of 153 characters of text\n",
      "don had 1 pieces of work with a total of 5180 characters of text\n",
      "donation had 1 pieces of work with a total of 3147 characters of text\n",
      "dracontius had 16 pieces of work with a total of 45692 characters of text\n",
      "dumdiane had 1 pieces of work with a total of 259 characters of text\n",
      "dumdomus had 1 pieces of work with a total of 65 characters of text\n",
      "ebulo had 1 pieces of work with a total of 14004 characters of text\n",
      "egeria had 1 pieces of work with a total of 11242 characters of text\n",
      "ein had 1 pieces of work with a total of 8987 characters of text\n",
      "enn had 1 pieces of work with a total of 1439 characters of text\n",
      "ennius had 1 pieces of work with a total of 3811 characters of text\n",
      "ennodius had 1 pieces of work with a total of 13006 characters of text\n",
      "ep had 1 pieces of work with a total of 3291 characters of text\n",
      "epistaustras had 1 pieces of work with a total of 5319 characters of text\n",
      "epitaphs had 1 pieces of work with a total of 2235 characters of text\n",
      "epitomecononiana had 1 pieces of work with a total of 6930 characters of text\n",
      "epitomefeliciana had 1 pieces of work with a total of 7764 characters of text\n",
      "erasmus had 1 pieces of work with a total of 5576 characters of text\n",
      "erchempert had 1 pieces of work with a total of 14564 characters of text\n",
      "estas had 1 pieces of work with a total of 105 characters of text\n",
      "eucherius had 1 pieces of work with a total of 4755 characters of text\n",
      "eugenius had 1 pieces of work with a total of 100 characters of text\n",
      "eugippius had 1 pieces of work with a total of 13762 characters of text\n",
      "eutropius had 1 pieces of work with a total of 21868 characters of text\n",
      "exivi had 1 pieces of work with a total of 4912 characters of text\n",
      "fabe had 1 pieces of work with a total of 6053 characters of text\n",
      "falcandus had 1 pieces of work with a total of 41670 characters of text\n",
      "falcone had 1 pieces of work with a total of 44690 characters of text\n",
      "faustoandrelino had 1 pieces of work with a total of 801 characters of text\n",
      "ferraria had 1 pieces of work with a total of 3220 characters of text\n",
      "ficino had 1 pieces of work with a total of 3983 characters of text\n",
      "fletcher had 1 pieces of work with a total of 7096 characters of text\n",
      "florus had 1 pieces of work with a total of 30973 characters of text\n",
      "foedusaeternum had 1 pieces of work with a total of 561 characters of text\n",
      "forsett had 1 pieces of work with a total of 6118 characters of text\n",
      "fortunat had 1 pieces of work with a total of 116 characters of text\n",
      "fragmentumlaurentianum had 1 pieces of work with a total of 954 characters of text\n",
      "fredegarius had 1 pieces of work with a total of 27300 characters of text\n",
      "frodebertus had 1 pieces of work with a total of 1227 characters of text\n",
      "frontinus had 1 pieces of work with a total of 421 characters of text\n",
      "fronto had 1 pieces of work with a total of 54465 characters of text\n",
      "fulbert had 1 pieces of work with a total of 123 characters of text\n",
      "fulgentius had 1 pieces of work with a total of 5993 characters of text\n",
      "gaius had 1 pieces of work with a total of 15402 characters of text\n",
      "galileo had 1 pieces of work with a total of 12487 characters of text\n",
      "garcilaso had 1 pieces of work with a total of 1165 characters of text\n",
      "garland had 1 pieces of work with a total of 3760 characters of text\n",
      "gaud had 1 pieces of work with a total of 154 characters of text\n",
      "gauss had 1 pieces of work with a total of 12162 characters of text\n",
      "gellius had 21 pieces of work with a total of 137854 characters of text\n",
      "germanicus had 1 pieces of work with a total of 5622 characters of text\n",
      "gestafrancorum had 1 pieces of work with a total of 1403 characters of text\n",
      "gestarom had 1 pieces of work with a total of 19688 characters of text\n",
      "gioacchino had 1 pieces of work with a total of 25292 characters of text\n",
      "girolamoaccelini had 1 pieces of work with a total of 38723 characters of text\n",
      "girolamoamaseo had 1 pieces of work with a total of 2798 characters of text\n",
      "glass had 1 pieces of work with a total of 31324 characters of text\n",
      "godfrey had 1 pieces of work with a total of 1822 characters of text\n",
      "grattius had 1 pieces of work with a total of 4243 characters of text\n",
      "gravissimas had 1 pieces of work with a total of 2096 characters of text\n",
      "greg had 1 pieces of work with a total of 897 characters of text\n",
      "gregdecretals had 1 pieces of work with a total of 37625 characters of text\n",
      "gregory had 1 pieces of work with a total of 18319 characters of text\n",
      "gregorytours had 1 pieces of work with a total of 9668 characters of text\n",
      "gwinne had 1 pieces of work with a total of 8072 characters of text\n",
      "halley had 1 pieces of work with a total of 369 characters of text\n",
      "hebet had 1 pieces of work with a total of 121 characters of text\n",
      "henry had 1 pieces of work with a total of 1371 characters of text\n",
      "henrysettimello had 1 pieces of work with a total of 8194 characters of text\n",
      "hipp had 1 pieces of work with a total of 2792 characters of text\n",
      "histapoll had 1 pieces of work with a total of 14613 characters of text\n",
      "histbrit had 1 pieces of work with a total of 11314 characters of text\n",
      "holberg had 1 pieces of work with a total of 34977 characters of text\n",
      "horace had 10 pieces of work with a total of 52219 characters of text\n",
      "hrabanus had 1 pieces of work with a total of 206 characters of text\n",
      "hugo had 1 pieces of work with a total of 6453 characters of text\n",
      "hydatiuschronicon had 1 pieces of work with a total of 6571 characters of text\n",
      "hydatiusfasti had 1 pieces of work with a total of 10086 characters of text\n",
      "hyginus had 1 pieces of work with a total of 3878 characters of text\n",
      "hymni had 1 pieces of work with a total of 2136 characters of text\n",
      "iabervocius had 1 pieces of work with a total of 770 characters of text\n",
      "iamdulcis had 1 pieces of work with a total of 232 characters of text\n",
      "ilias had 1 pieces of work with a total of 7615 characters of text\n",
      "index had 1 pieces of work with a total of 213 characters of text\n",
      "indices had 1 pieces of work with a total of 246 characters of text\n",
      "innocent had 1 pieces of work with a total of 18725 characters of text\n",
      "inquisitio had 1 pieces of work with a total of 4941 characters of text\n",
      "inscriptions had 1 pieces of work with a total of 1215 characters of text\n",
      "iordanes had 1 pieces of work with a total of 21090 characters of text\n",
      "ipsavivere had 1 pieces of work with a total of 99 characters of text\n",
      "isidore had 1 pieces of work with a total of 23566 characters of text\n",
      "italicus had 1 pieces of work with a total of 7605 characters of text\n",
      "jacopoallegretti had 1 pieces of work with a total of 837 characters of text\n",
      "janus had 1 pieces of work with a total of 943 characters of text\n",
      "jerome had 80 pieces of work with a total of 1041707 characters of text\n",
      "jfkhonor had 1 pieces of work with a total of 272 characters of text\n",
      "johannes had 1 pieces of work with a total of 14602 characters of text\n",
      "junillus had 1 pieces of work with a total of 13641 characters of text\n",
      "justin had 1 pieces of work with a total of 1203 characters of text\n",
      "justinian had 1 pieces of work with a total of 22680 characters of text\n",
      "juvenal had 1 pieces of work with a total of 29189 characters of text\n",
      "juvencus had 4 pieces of work with a total of 23355 characters of text\n",
      "kalila had 1 pieces of work with a total of 36502 characters of text\n",
      "kempis had 1 pieces of work with a total of 6191 characters of text\n",
      "kepler had 1 pieces of work with a total of 7555 characters of text\n",
      "lactantius had 1 pieces of work with a total of 13175 characters of text\n",
      "landor had 1 pieces of work with a total of 3837 characters of text\n",
      "legenda had 1 pieces of work with a total of 3821 characters of text\n",
      "leo had 1 pieces of work with a total of 6667 characters of text\n",
      "leothegreat had 1 pieces of work with a total of 1205 characters of text\n",
      "letabundus had 1 pieces of work with a total of 162 characters of text\n",
      "levis had 1 pieces of work with a total of 114 characters of text\n",
      "lhomond had 1 pieces of work with a total of 33933 characters of text\n",
      "liberpontificalis had 1 pieces of work with a total of 19308 characters of text\n",
      "livy had 4 pieces of work with a total of 592961 characters of text\n",
      "lotichius had 1 pieces of work with a total of 182 characters of text\n",
      "lucan had 10 pieces of work with a total of 62938 characters of text\n",
      "lucernarium had 1 pieces of work with a total of 90 characters of text\n",
      "lucretius had 6 pieces of work with a total of 55778 characters of text\n",
      "luther had 1 pieces of work with a total of 894 characters of text\n",
      "macarius had 1 pieces of work with a total of 6172 characters of text\n",
      "macrobius had 8 pieces of work with a total of 102569 characters of text\n",
      "magnacarta had 1 pieces of work with a total of 4287 characters of text\n",
      "maidstone had 1 pieces of work with a total of 2047 characters of text\n",
      "malaterra had 1 pieces of work with a total of 11862 characters of text\n",
      "manilius had 5 pieces of work with a total of 31644 characters of text\n",
      "mapps had 1 pieces of work with a total of 1983 characters of text\n",
      "marbodus had 1 pieces of work with a total of 2107 characters of text\n",
      "marcantonioaldegati had 1 pieces of work with a total of 8863 characters of text\n",
      "marcellinus had 1 pieces of work with a total of 11561 characters of text\n",
      "marcusmincuiusfelix had 1 pieces of work with a total of 13821 characters of text\n",
      "martial had 14 pieces of work with a total of 50707 characters of text\n",
      "martinbraga had 1 pieces of work with a total of 1472 characters of text\n",
      "marullo had 1 pieces of work with a total of 470 characters of text\n",
      "marx had 1 pieces of work with a total of 1017 characters of text\n",
      "maximianus had 1 pieces of work with a total of 5099 characters of text\n",
      "may had 1 pieces of work with a total of 3897 characters of text\n",
      "melanchthon had 1 pieces of work with a total of 2106 characters of text\n",
      "milton had 1 pieces of work with a total of 1761 characters of text\n",
      "minucius had 1 pieces of work with a total of 14018 characters of text\n",
      "mirabilia had 1 pieces of work with a total of 5182 characters of text\n",
      "mirandola had 1 pieces of work with a total of 65 characters of text\n",
      "montanus had 1 pieces of work with a total of 966 characters of text\n",
      "more had 1 pieces of work with a total of 33136 characters of text\n",
      "musavenit had 1 pieces of work with a total of 117 characters of text\n",
      "naevius had 1 pieces of work with a total of 1036 characters of text\n",
      "navagero had 1 pieces of work with a total of 8263 characters of text\n",
      "nemesianus had 1 pieces of work with a total of 690 characters of text\n",
      "nepos had 1 pieces of work with a total of 33582 characters of text\n",
      "newton had 1 pieces of work with a total of 669 characters of text\n",
      "nithardus had 1 pieces of work with a total of 3559 characters of text\n",
      "nobilis had 1 pieces of work with a total of 114 characters of text\n",
      "notitia had 1 pieces of work with a total of 6058 characters of text\n",
      "novatian had 1 pieces of work with a total of 24333 characters of text\n",
      "obsequens had 1 pieces of work with a total of 6643 characters of text\n",
      "omnegenus had 1 pieces of work with a total of 216 characters of text\n",
      "oratio had 1 pieces of work with a total of 1028 characters of text\n",
      "oresmius had 1 pieces of work with a total of 11491 characters of text\n",
      "origo had 1 pieces of work with a total of 1229 characters of text\n",
      "orosius had 1 pieces of work with a total of 12399 characters of text\n",
      "ottofreising had 1 pieces of work with a total of 18211 characters of text\n",
      "ovid had 41 pieces of work with a total of 268300 characters of text\n",
      "owen had 1 pieces of work with a total of 604 characters of text\n",
      "paris had 1 pieces of work with a total of 832 characters of text\n",
      "pascoli had 1 pieces of work with a total of 1094 characters of text\n",
      "passerat had 1 pieces of work with a total of 607 characters of text\n",
      "patricius had 1 pieces of work with a total of 4333 characters of text\n",
      "pauldeacon had 1 pieces of work with a total of 2228 characters of text\n",
      "paulinus had 1 pieces of work with a total of 30411 characters of text\n",
      "paulusdiaconus had 1 pieces of work with a total of 11632 characters of text\n",
      "perp had 1 pieces of work with a total of 4314 characters of text\n",
      "persius had 1 pieces of work with a total of 5596 characters of text\n",
      "pervig had 1 pieces of work with a total of 772 characters of text\n",
      "petrarch had 1 pieces of work with a total of 1088 characters of text\n",
      "petrarchmedicus had 1 pieces of work with a total of 27546 characters of text\n",
      "petronius had 1 pieces of work with a total of 36066 characters of text\n",
      "petroniusfrag had 1 pieces of work with a total of 1455 characters of text\n",
      "phaedr had 1 pieces of work with a total of 1220 characters of text\n",
      "phaedrapp had 1 pieces of work with a total of 3279 characters of text\n",
      "piccolomini had 1 pieces of work with a total of 731 characters of text\n",
      "planctus had 1 pieces of work with a total of 541 characters of text\n",
      "plautus had 20 pieces of work with a total of 210574 characters of text\n",
      "pliny had 1 pieces of work with a total of 7723 characters of text\n",
      "plinytheelder had 7 pieces of work with a total of 475768 characters of text\n",
      "plinytheyounger had 10 pieces of work with a total of 79798 characters of text\n",
      "poggio had 1 pieces of work with a total of 17048 characters of text\n",
      "polignac had 3 pieces of work with a total of 152574 characters of text\n",
      "pomponius had 1 pieces of work with a total of 7085 characters of text\n",
      "pontano had 1 pieces of work with a total of 1159 characters of text\n",
      "poree had 1 pieces of work with a total of 11176 characters of text\n",
      "porphyrius had 1 pieces of work with a total of 6102 characters of text\n",
      "potatores had 1 pieces of work with a total of 188 characters of text\n",
      "prataiam had 1 pieces of work with a total of 149 characters of text\n",
      "prec had 1 pieces of work with a total of 265 characters of text\n",
      "precatio had 1 pieces of work with a total of 148 characters of text\n",
      "priapea had 1 pieces of work with a total of 4429 characters of text\n",
      "priscian had 4 pieces of work with a total of 20747 characters of text\n",
      "professio had 1 pieces of work with a total of 1385 characters of text\n",
      "prop had 1 pieces of work with a total of 7315 characters of text\n",
      "propertius had 1 pieces of work with a total of 30354 characters of text\n",
      "prosperus had 1 pieces of work with a total of 5264 characters of text\n",
      "protospatarius had 1 pieces of work with a total of 5234 characters of text\n",
      "prudentius had 7 pieces of work with a total of 38688 characters of text\n",
      "pseudocicero had 1 pieces of work with a total of 2195 characters of text\n",
      "pseudoquintilian had 1 pieces of work with a total of 83064 characters of text\n",
      "psplato had 1 pieces of work with a total of 1768 characters of text\n",
      "pulchracomis had 1 pieces of work with a total of 37 characters of text\n",
      "qcicero had 1 pieces of work with a total of 4988 characters of text\n",
      "quintilian had 12 pieces of work with a total of 207913 characters of text\n",
      "quum had 1 pieces of work with a total of 368 characters of text\n",
      "raoul had 1 pieces of work with a total of 45260 characters of text\n",
      "regula had 1 pieces of work with a total of 7139 characters of text\n",
      "reposianus had 1 pieces of work with a total of 1542 characters of text\n",
      "resgestae had 1 pieces of work with a total of 3096 characters of text\n",
      "rhetores had 1 pieces of work with a total of 113 characters of text\n",
      "richerus had 1 pieces of work with a total of 14512 characters of text\n",
      "rimbaud had 1 pieces of work with a total of 502 characters of text\n",
      "ruaeus had 1 pieces of work with a total of 3041 characters of text\n",
      "rumor had 1 pieces of work with a total of 157 characters of text\n",
      "rutilius had 1 pieces of work with a total of 4643 characters of text\n",
      "rutiliuslupus had 1 pieces of work with a total of 5502 characters of text\n",
      "sabinus had 1 pieces of work with a total of 895 characters of text\n",
      "sall had 1 pieces of work with a total of 25681 characters of text\n",
      "sallust had 3 pieces of work with a total of 42735 characters of text\n",
      "sannazaro had 1 pieces of work with a total of 11445 characters of text\n",
      "scaliger had 1 pieces of work with a total of 49 characters of text\n",
      "scbaccanalibus had 1 pieces of work with a total of 1093 characters of text\n",
      "scottus had 1 pieces of work with a total of 289 characters of text\n",
      "scriptoreshistoriaeaugustae had 4 pieces of work with a total of 86648 characters of text\n",
      "sedulius had 1 pieces of work with a total of 2324 characters of text\n",
      "sen had 1 pieces of work with a total of 8864 characters of text\n",
      "seneca had 42 pieces of work with a total of 385030 characters of text\n",
      "senecatheelder had 8 pieces of work with a total of 119085 characters of text\n",
      "septsap had 1 pieces of work with a total of 9427 characters of text\n",
      "serviushonoratus had 4 pieces of work with a total of 65032 characters of text\n",
      "sha had 1 pieces of work with a total of 6856 characters of text\n",
      "sicmeafata had 1 pieces of work with a total of 155 characters of text\n",
      "sidonius had 1 pieces of work with a total of 3027 characters of text\n",
      "sigebert had 1 pieces of work with a total of 1729 characters of text\n",
      "silius had 1 pieces of work with a total of 6763 characters of text\n",
      "siliusitalicus had 17 pieces of work with a total of 88590 characters of text\n",
      "simedignetur had 1 pieces of work with a total of 58 characters of text\n",
      "smarius had 1 pieces of work with a total of 1251 characters of text\n",
      "solet had 1 pieces of work with a total of 1975 characters of text\n",
      "solinus had 1 pieces of work with a total of 10207 characters of text\n",
      "spinoza had 1 pieces of work with a total of 14848 characters of text\n",
      "statius had 18 pieces of work with a total of 110251 characters of text\n",
      "suetonius had 12 pieces of work with a total of 80771 characters of text\n",
      "sulpicia had 1 pieces of work with a total of 326 characters of text\n",
      "sulpiciusseveruschron had 1 pieces of work with a total of 16313 characters of text\n",
      "sulpiciusseverusmartin had 1 pieces of work with a total of 8498 characters of text\n",
      "suscipeflos had 1 pieces of work with a total of 85 characters of text\n",
      "syrus had 1 pieces of work with a total of 10369 characters of text\n",
      "tacitus had 20 pieces of work with a total of 188319 characters of text\n",
      "tempusest had 1 pieces of work with a total of 247 characters of text\n",
      "ter had 1 pieces of work with a total of 10143 characters of text\n",
      "terence had 6 pieces of work with a total of 63599 characters of text\n",
      "terraiam had 1 pieces of work with a total of 198 characters of text\n",
      "tertullian had 2 pieces of work with a total of 31118 characters of text\n",
      "testamentum had 1 pieces of work with a total of 396 characters of text\n",
      "tevigilans had 1 pieces of work with a total of 71 characters of text\n",
      "theganus had 1 pieces of work with a total of 7630 characters of text\n",
      "theodolus had 1 pieces of work with a total of 2754 characters of text\n",
      "theodosius had 1 pieces of work with a total of 12411 characters of text\n",
      "theophanes had 1 pieces of work with a total of 347 characters of text\n",
      "thesauro had 1 pieces of work with a total of 2112 characters of text\n",
      "thomasedessa had 1 pieces of work with a total of 12859 characters of text\n",
      "tibullus had 1 pieces of work with a total of 14712 characters of text\n",
      "tunger had 1 pieces of work with a total of 15315 characters of text\n",
      "valeriusflaccus had 8 pieces of work with a total of 42426 characters of text\n",
      "valeriusmaximus had 9 pieces of work with a total of 90973 characters of text\n",
      "valesianus had 1 pieces of work with a total of 3594 characters of text\n",
      "valmax had 1 pieces of work with a total of 8787 characters of text\n",
      "varro had 1 pieces of work with a total of 7636 characters of text\n",
      "vegetius had 1 pieces of work with a total of 5459 characters of text\n",
      "vegius had 1 pieces of work with a total of 5138 characters of text\n",
      "vell had 1 pieces of work with a total of 27392 characters of text\n",
      "venantius had 1 pieces of work with a total of 875 characters of text\n",
      "vergil had 17 pieces of work with a total of 99997 characters of text\n",
      "vicentius had 1 pieces of work with a total of 20418 characters of text\n",
      "vico had 1 pieces of work with a total of 3727 characters of text\n",
      "victor had 1 pieces of work with a total of 11244 characters of text\n",
      "vida had 1 pieces of work with a total of 5155 characters of text\n",
      "vitacaroli had 1 pieces of work with a total of 17896 characters of text\n",
      "vitruvius had 10 pieces of work with a total of 67461 characters of text\n",
      "volovirum had 1 pieces of work with a total of 197 characters of text\n",
      "voragine had 1 pieces of work with a total of 512 characters of text\n",
      "waardenburg had 1 pieces of work with a total of 668 characters of text\n",
      "waltarius had 1 pieces of work with a total of 2988 characters of text\n",
      "walter had 1 pieces of work with a total of 498 characters of text\n",
      "walton had 1 pieces of work with a total of 4541 characters of text\n",
      "williamapulia had 1 pieces of work with a total of 20635 characters of text\n",
      "williamtyre had 1 pieces of work with a total of 1194 characters of text\n",
      "withof had 1 pieces of work with a total of 274 characters of text\n",
      "wmconchesdogma had 1 pieces of work with a total of 16159 characters of text\n",
      "wmconchesphil had 1 pieces of work with a total of 7051 characters of text\n",
      "xanten had 1 pieces of work with a total of 8094 characters of text\n",
      "xylander had 1 pieces of work with a total of 17623 characters of text\n",
      "zonaras had 1 pieces of work with a total of 12912 characters of text\n"
     ]
    }
   ],
   "source": [
    "CI = dataExp.CorpusInterface(corpus_name=\"tokenized_corpus.pickle\", shouldTokenize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5945bd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T16:40:50.134424Z",
     "iopub.status.busy": "2023-03-26T16:40:50.134138Z",
     "iopub.status.idle": "2023-03-26T16:40:51.824319Z",
     "shell.execute_reply": "2023-03-26T16:40:51.823627Z",
     "shell.execute_reply.started": "2023-03-26T16:40:50.134402Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /notebooks/LatinBERT/latin_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m LatinTokenizer(encoder)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForMaskedLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(bertPath)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizerPath = os.getcwd()+\"/LatinBERT/latin.subword.encoder\"\n",
    "bertPath = os.getcwd()+\"/LatinBERT/latin_bert\"\n",
    "encoder = text_encoder.SubwordTextEncoder(tokenizerPath)\n",
    "tokenizer = LatinTokenizer(encoder)\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(bertPath)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38e419c-5b27-4eef-993a-a41b5a59f5c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:39:13.134774Z",
     "iopub.status.busy": "2023-03-26T00:39:13.134506Z",
     "iopub.status.idle": "2023-03-26T00:39:13.151282Z",
     "shell.execute_reply": "2023-03-26T00:39:13.150287Z",
     "shell.execute_reply.started": "2023-03-26T00:39:13.134753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '[PAD]',\n",
       " 1: '[UNK]',\n",
       " 2: '[CLS]',\n",
       " 3: '[SEP]',\n",
       " 4: '[MASK]',\n",
       " 5: '<pad>_',\n",
       " 6: '<EOS>_',\n",
       " 7: ',_',\n",
       " 8: '._',\n",
       " 9: '_',\n",
       " 10: 'et_',\n",
       " 11: '-_',\n",
       " 12: 'in_',\n",
       " 13: ';_',\n",
       " 14: 's_',\n",
       " 15: 'est_',\n",
       " 16: 'a_',\n",
       " 17: ':_',\n",
       " 18: 'ne_',\n",
       " 19: 'i_',\n",
       " 20: 'non_',\n",
       " 21: 'm_',\n",
       " 22: 'ad_',\n",
       " 23: 'e_',\n",
       " 24: 'o_',\n",
       " 25: 'quod_',\n",
       " 26: ')_',\n",
       " 27: 'um_',\n",
       " 28: '^_',\n",
       " 29: 't_',\n",
       " 30: 'de_',\n",
       " 31: 'ut_',\n",
       " 32: '(_',\n",
       " 33: '&_',\n",
       " 34: 'us_',\n",
       " 35: 'que_',\n",
       " 36: 'cum_',\n",
       " 37: 'is_',\n",
       " 38: 'qui_',\n",
       " 39: 'sed_',\n",
       " 40: 'si_',\n",
       " 41: 'ex_',\n",
       " 42: 'per_',\n",
       " 43: 'quae_',\n",
       " 44: 'apos_',\n",
       " 45: '\"_',\n",
       " 46: '?_',\n",
       " 47: 'hoc_',\n",
       " 48: '1_',\n",
       " 49: 'sunt_',\n",
       " 50: 'esse_',\n",
       " 51: 'c_',\n",
       " 52: 'se_',\n",
       " 53: 'autem_',\n",
       " 54: 'enim_',\n",
       " 55: 'quam_',\n",
       " 56: 'quia_',\n",
       " 57: '2_',\n",
       " 58: '*_',\n",
       " 59: 're_',\n",
       " 60: ']_',\n",
       " 61: 'vel_',\n",
       " 62: 'es_',\n",
       " 63: 'ab_',\n",
       " 64: 'r_',\n",
       " 65: 'etiam_',\n",
       " 66: '_',\n",
       " 67: 'tur_',\n",
       " 68: 'nt_',\n",
       " 69: 'am_',\n",
       " 70: 'it_',\n",
       " 71: '3_',\n",
       " 72: 'te_',\n",
       " 73: '[_',\n",
       " 74: 'sit_',\n",
       " 75: 'p_',\n",
       " 76: 'l_',\n",
       " 77: 'ur_',\n",
       " 78: '4_',\n",
       " 79: '_',\n",
       " 80: 'bus_',\n",
       " 81: 'em_',\n",
       " 82: 'aut_',\n",
       " 83: 'at_',\n",
       " 84: 'v_',\n",
       " 85: 'os_',\n",
       " 86: 'nec_',\n",
       " 87: 'd_',\n",
       " 88: 'pro_',\n",
       " 89: 'ae_',\n",
       " 90: 'quo_',\n",
       " 91: 'rum_',\n",
       " 92: 'ergo_',\n",
       " 93: '5_',\n",
       " 94: '_',\n",
       " 95: 'id_',\n",
       " 96: 'ac_',\n",
       " 97: 'me_',\n",
       " 98: \"'_\",\n",
       " 99: 'quid_',\n",
       " 100: '6_',\n",
       " 101: 'ii_',\n",
       " 102: 'sic_',\n",
       " 103: 'ita_',\n",
       " 104: 'mus_',\n",
       " 105: 'unt_',\n",
       " 106: 'sicut_',\n",
       " 107: 'tamen_',\n",
       " 108: 'atque_',\n",
       " 109: 'secundum_',\n",
       " 110: 'as_',\n",
       " 111: '8_',\n",
       " 112: 'nam_',\n",
       " 113: '7_',\n",
       " 114: 'dei_',\n",
       " 115: 'eo_',\n",
       " 116: 'orum_',\n",
       " 117: 'u_',\n",
       " 118: 'ns_',\n",
       " 119: 'erat_',\n",
       " 120: 'q_',\n",
       " 121: 'n_',\n",
       " 122: 'anno_',\n",
       " 123: 'haec_',\n",
       " 124: '9_',\n",
       " 125: 'dicit_',\n",
       " 126: 'b_',\n",
       " 127: 'io_',\n",
       " 128: 'ea_',\n",
       " 129: 'f_',\n",
       " 130: 'ri_',\n",
       " 131: 'qua_',\n",
       " 132: 'vero_',\n",
       " 133: 'fuit_',\n",
       " 134: 'x_',\n",
       " 135: 'tum_',\n",
       " 136: 'amp_',\n",
       " 137: 'inter_',\n",
       " 138: 'quot_',\n",
       " 139: 'ejus_',\n",
       " 140: 'potest_',\n",
       " 141: 'eum_',\n",
       " 142: 'unde_',\n",
       " 143: 'nisi_',\n",
       " 144: 'nos_',\n",
       " 145: 'quibus_',\n",
       " 146: 'deus_',\n",
       " 147: 'quidem_',\n",
       " 148: 'j_',\n",
       " 149: 'ei_',\n",
       " 150: 'dum_',\n",
       " 151: '/_',\n",
       " 152: '\\\\\\\\_',\n",
       " 153: 'die_',\n",
       " 154: 'eius_',\n",
       " 155: 'ipse_',\n",
       " 156: 'modo_',\n",
       " 157: 'post_',\n",
       " 158: 'ntur_',\n",
       " 159: 'tis_',\n",
       " 160: 'ibus_',\n",
       " 161: 'g_',\n",
       " 162: 'super_',\n",
       " 163: 'dicitur_',\n",
       " 164: 'omnia_',\n",
       " 165: 'y_',\n",
       " 166: 'neque_',\n",
       " 167: 'omnes_',\n",
       " 168: 'hic_',\n",
       " 169: 'nobis_',\n",
       " 170: 'contra_',\n",
       " 171: 'ubi_',\n",
       " 172: 'h_',\n",
       " 173: 'vit_',\n",
       " 174: 'apud_',\n",
       " 175: 'gt_',\n",
       " 176: 'propter_',\n",
       " 177: 'iam_',\n",
       " 178: 'sibi_',\n",
       " 179: 'his_',\n",
       " 180: 'quem_',\n",
       " 181: 'eorum_',\n",
       " 182: 'mihi_',\n",
       " 183: 'or_',\n",
       " 184: 'ta_',\n",
       " 185: 'nihil_',\n",
       " 186: 'ego_',\n",
       " 187: 'igitur_',\n",
       " 188: 'sine_',\n",
       " 189: 'ideo_',\n",
       " 190: 'deo_',\n",
       " 191: 'nunc_',\n",
       " 192: 'erit_',\n",
       " 193: 'ante_',\n",
       " 194: 'tibi_',\n",
       " 195: 'ti_',\n",
       " 196: 'ia_',\n",
       " 197: 'illa_',\n",
       " 198: 'res_',\n",
       " 199: 'di_',\n",
       " 200: 'tu_',\n",
       " 201: 'iii_',\n",
       " 202: 'an_',\n",
       " 203: 'illud_',\n",
       " 204: 'tam_',\n",
       " 205: 'ni_',\n",
       " 206: 'vi_',\n",
       " 207: 'quasi_',\n",
       " 208: 'lib_',\n",
       " 209: 'quoque_',\n",
       " 210: 'habet_',\n",
       " 211: 'ille_',\n",
       " 212: 'eos_',\n",
       " 213: 'ant_',\n",
       " 214: 'to_',\n",
       " 215: 'quis_',\n",
       " 216: '10_',\n",
       " 217: 'esset_',\n",
       " 218: 'omnibus_',\n",
       " 219: 'dominus_',\n",
       " 220: 'lt_',\n",
       " 221: 'magis_',\n",
       " 222: '0_',\n",
       " 223: 'ibi_',\n",
       " 224: 'scilicet_',\n",
       " 225: 'sua_',\n",
       " 226: 'ret_',\n",
       " 227: 'bat_',\n",
       " 228: 'ere_',\n",
       " 229: 'alia_',\n",
       " 230: 'videtur_',\n",
       " 231: 'sub_',\n",
       " 232: 'idem_',\n",
       " 233: 'sive_',\n",
       " 234: 'causa_',\n",
       " 235: '_',\n",
       " 236: '!_',\n",
       " 237: 'ter_',\n",
       " 238: 'er_',\n",
       " 239: 'tantum_',\n",
       " 240: 'cap_',\n",
       " 241: 'primo_',\n",
       " 242: 'do_',\n",
       " 243: 'ipsa_',\n",
       " 244: 'deum_',\n",
       " 245: 'nis_',\n",
       " 246: 'primum_',\n",
       " 247: 'eam_',\n",
       " 248: 'iv_',\n",
       " 249: 'la_',\n",
       " 250: 'ra_',\n",
       " 251: 'sse_',\n",
       " 252: 'ius_',\n",
       " 253: 'eis_',\n",
       " 254: 'le_',\n",
       " 255: 'homo_',\n",
       " 256: 'tus_',\n",
       " 257: '11_',\n",
       " 258: 'ct_',\n",
       " 259: 'aliquid_',\n",
       " 260: 'quos_',\n",
       " 261: 'semper_',\n",
       " 262: 'jam_',\n",
       " 263: 'cui_',\n",
       " 264: 'tempore_',\n",
       " 265: 've_',\n",
       " 266: 'k_',\n",
       " 267: 'quantum_',\n",
       " 268: '12_',\n",
       " 269: 'ait_',\n",
       " 270: 'ipsum_',\n",
       " 271: '|_',\n",
       " 272: 'suo_',\n",
       " 273: 'domini_',\n",
       " 274: 'nem_',\n",
       " 275: 'unum_',\n",
       " 276: 'loco_',\n",
       " 277: 'illi_',\n",
       " 278: 'supra_',\n",
       " 279: 'usque_',\n",
       " 280: 'christi_',\n",
       " 281: '15_',\n",
       " 282: 'rem_',\n",
       " 283: 'tunc_',\n",
       " 284: 'aliis_',\n",
       " 285: 'nomen_',\n",
       " 286: 'solum_',\n",
       " 287: 'dicendum_',\n",
       " 288: 'sint_',\n",
       " 289: 'quando_',\n",
       " 290: 'untur_',\n",
       " 291: 'suis_',\n",
       " 292: 'li_',\n",
       " 293: 'iis_',\n",
       " 294: 'dixit_',\n",
       " 295: 'una_',\n",
       " 296: 'vos_',\n",
       " 297: 'hac_',\n",
       " 298: 'etc_',\n",
       " 299: 'ium_',\n",
       " 300: 'hanc_',\n",
       " 301: '14_',\n",
       " 302: 'erunt_',\n",
       " 303: 'quoniam_',\n",
       " 304: 'circa_',\n",
       " 305: 'suam_',\n",
       " 306: 'no_',\n",
       " 307: '_',\n",
       " 308: '20_',\n",
       " 309: 'parte_',\n",
       " 310: 'num_',\n",
       " 311: 'tio_',\n",
       " 312: 'deinde_',\n",
       " 313: 'sum_',\n",
       " 314: 'filius_',\n",
       " 315: 'suum_',\n",
       " 316: 'ue_',\n",
       " 317: 'rerum_',\n",
       " 318: '13_',\n",
       " 319: 'co_',\n",
       " 320: '16_',\n",
       " 321: 'atur_',\n",
       " 322: 'corpus_',\n",
       " 323: 'dictum_',\n",
       " 324: 'erant_',\n",
       " 325: 'da_',\n",
       " 326: 'pater_',\n",
       " 327: 'tes_',\n",
       " 328: 'na_',\n",
       " 329: 'item_',\n",
       " 330: 'aliud_',\n",
       " 331: 'fit_',\n",
       " 332: 'vobis_',\n",
       " 333: 'illis_',\n",
       " 334: 'ipso_',\n",
       " 335: 'omnium_',\n",
       " 336: '17_',\n",
       " 337: 'alii_',\n",
       " 338: 'sui_',\n",
       " 339: 'ca_',\n",
       " 340: 'nomine_',\n",
       " 341: 'tua_',\n",
       " 342: 'terra_',\n",
       " 343: 'omnis_',\n",
       " 344: 'tas_',\n",
       " 345: 'ce_',\n",
       " 346: 'itaque_',\n",
       " 347: 'bonum_',\n",
       " 348: 'om_',\n",
       " 349: 'fuerit_',\n",
       " 350: 'inquit_',\n",
       " 351: 'bant_',\n",
       " 352: 'lis_',\n",
       " 353: 'minus_',\n",
       " 354: 'fuisse_',\n",
       " 355: '25_',\n",
       " 356: 'inde_',\n",
       " 357: 'tem_',\n",
       " 358: 'verum_',\n",
       " 359: 'ris_',\n",
       " 360: 'the_',\n",
       " 361: 'natura_',\n",
       " 362: 'quas_',\n",
       " 363: 'spiritus_',\n",
       " 364: 'homines_',\n",
       " 365: 'eadem_',\n",
       " 366: 'licet_',\n",
       " 367: '18_',\n",
       " 368: 'el_',\n",
       " 369: 'praeterea_',\n",
       " 370: 'ratio_',\n",
       " 371: 'ipsi_',\n",
       " 372: 'itur_',\n",
       " 373: 'domino_',\n",
       " 374: 'seu_',\n",
       " 375: 'ratione_',\n",
       " 376: 'cor_',\n",
       " 377: 'dies_',\n",
       " 378: 'possit_',\n",
       " 379: '^^_',\n",
       " 380: 'rebus_',\n",
       " 381: 'bene_',\n",
       " 382: 'verba_',\n",
       " 383: 'facit_',\n",
       " 384: 'rei_',\n",
       " 385: 'duo_',\n",
       " 386: 'ndum_',\n",
       " 387: 'cf_',\n",
       " 388: 'cuius_',\n",
       " 389: 'illo_',\n",
       " 390: 'ens_',\n",
       " 391: 'pars_',\n",
       " 392: '.&_',\n",
       " 393: 'ent_',\n",
       " 394: 'mea_',\n",
       " 395: 'fieri_',\n",
       " 396: 'caput_',\n",
       " 397: 'ui_',\n",
       " 398: 'gratia_',\n",
       " 399: 'eodem_',\n",
       " 400: 'ntes_',\n",
       " 401: 'quum_',\n",
       " 402: '19_',\n",
       " 403: 'onem_',\n",
       " 404: 'hunc_',\n",
       " 405: 'ista_',\n",
       " 406: 'omni_',\n",
       " 407: 'quomodo_',\n",
       " 408: 'vita_',\n",
       " 409: 'les_',\n",
       " 410: 'ecclesiae_',\n",
       " 411: 'mur_',\n",
       " 412: 'habere_',\n",
       " 413: 'adhuc_',\n",
       " 414: 'simul_',\n",
       " 415: 'im_',\n",
       " 416: 'nostri_',\n",
       " 417: 'ipsius_',\n",
       " 418: 'anima_',\n",
       " 419: 'uit_',\n",
       " 420: 'etur_',\n",
       " 421: 'tempus_',\n",
       " 422: 'secundo_',\n",
       " 423: 'posse_',\n",
       " 424: 'facta_',\n",
       " 425: 'prima_',\n",
       " 426: 'quorum_',\n",
       " 427: 'christus_',\n",
       " 428: 'nostra_',\n",
       " 429: 'ide_',\n",
       " 430: 'sancti_',\n",
       " 431: 'multa_',\n",
       " 432: 'maxime_',\n",
       " 433: 'fecit_',\n",
       " 434: 'ionem_',\n",
       " 435: 'ob_',\n",
       " 436: 'verbum_',\n",
       " 437: 'locum_',\n",
       " 438: 'opus_',\n",
       " 439: 'hi_',\n",
       " 440: 'ecclesia_',\n",
       " 441: 'natus_',\n",
       " 442: 'w_',\n",
       " 443: 'illum_',\n",
       " 444: 'lo_',\n",
       " 445: 'z_',\n",
       " 446: '21_',\n",
       " 447: 'facere_',\n",
       " 448: '_',\n",
       " 449: 'mi_',\n",
       " 450: 'ci_',\n",
       " 451: 'hominum_',\n",
       " 452: 'ndo_',\n",
       " 453: 'prius_',\n",
       " 454: 'nm_',\n",
       " 455: 'quidam_',\n",
       " 456: 'sa_',\n",
       " 457: 'bona_',\n",
       " 458: '22_',\n",
       " 459: 'suae_',\n",
       " 460: '{_',\n",
       " 461: 'round_',\n",
       " 462: 'oportet_',\n",
       " 463: 'rex_',\n",
       " 464: 'possunt_',\n",
       " 465: 'satis_',\n",
       " 466: '_',\n",
       " 467: 'ndi_',\n",
       " 468: 'peccatum_',\n",
       " 469: 'ore_',\n",
       " 470: 'cujus_',\n",
       " 471: 'habent_',\n",
       " 472: 'postea_',\n",
       " 473: 'rent_',\n",
       " 474: 'nus_',\n",
       " 475: 'illius_',\n",
       " 476: 'factum_',\n",
       " 477: 'vis_',\n",
       " 478: '_',\n",
       " 479: 'domi_',\n",
       " 480: '24_',\n",
       " 481: 'hominis_',\n",
       " 482: 'uno_',\n",
       " 483: 'sti_',\n",
       " 484: 'dicere_',\n",
       " 485: '||_',\n",
       " 486: 'onis_',\n",
       " 487: 'corporis_',\n",
       " 488: 'unus_',\n",
       " 489: 'hinc_',\n",
       " 490: 'ro_',\n",
       " 491: 'vii_',\n",
       " 492: 'rationem_',\n",
       " 493: 'nulla_',\n",
       " 494: 'alio_',\n",
       " 495: 'debet_',\n",
       " 496: 'sset_',\n",
       " 497: '23_',\n",
       " 498: 'filii_',\n",
       " 499: 'sequitur_',\n",
       " 500: 'imus_',\n",
       " 501: 'ix_',\n",
       " 502: 'plus_',\n",
       " 503: 'patet_',\n",
       " 504: 'arum_',\n",
       " 505: 'hominem_',\n",
       " 506: 'quaedam_',\n",
       " 507: '27_',\n",
       " 508: 'filium_',\n",
       " 509: 'al_',\n",
       " 510: 'bis_',\n",
       " 511: 'fidem_',\n",
       " 512: 'sent_',\n",
       " 513: 'ed_',\n",
       " 514: 'christo_',\n",
       " 515: 'opera_',\n",
       " 516: 'potius_',\n",
       " 517: 'fi_',\n",
       " 518: 'huius_',\n",
       " 519: 'of_',\n",
       " 520: 'dominum_',\n",
       " 521: 'ma_',\n",
       " 522: '26_',\n",
       " 523: 'vitam_',\n",
       " 524: 'bit_',\n",
       " 525: '28_',\n",
       " 526: '=_',\n",
       " 527: 'quare_',\n",
       " 528: 'il_',\n",
       " 529: 'omnino_',\n",
       " 530: 'omne_',\n",
       " 531: 'cetera_',\n",
       " 532: 'genus_',\n",
       " 533: 'magna_',\n",
       " 534: 'qu_',\n",
       " 535: 'forte_',\n",
       " 536: 'terram_',\n",
       " 537: 'nes_',\n",
       " 538: 'utrum_',\n",
       " 539: 'mortem_',\n",
       " 540: 'ecce_',\n",
       " 541: 'vitae_',\n",
       " 542: 'modum_',\n",
       " 543: 'hujus_',\n",
       " 544: 'saepe_',\n",
       " 545: 'quamvis_',\n",
       " 546: 'verbis_',\n",
       " 547: 'forma_',\n",
       " 548: 'aliqua_',\n",
       " 549: 'batur_',\n",
       " 550: '_',\n",
       " 551: '30_',\n",
       " 552: 'nemo_',\n",
       " 553: 'xi_',\n",
       " 554: 'antur_',\n",
       " 555: 'cur_',\n",
       " 556: 'retur_',\n",
       " 557: 'illam_',\n",
       " 558: 'so_',\n",
       " 559: 'patris_',\n",
       " 560: 'totum_',\n",
       " 561: 'regione_',\n",
       " 562: 'partem_',\n",
       " 563: 'dicens_',\n",
       " 564: 'tres_',\n",
       " 565: 'vir_',\n",
       " 566: 'motus_',\n",
       " 567: 'ostendit_',\n",
       " 568: 'partes_',\n",
       " 569: 'recte_',\n",
       " 570: 'fidei_',\n",
       " 571: 'viii_',\n",
       " 572: 'corpore_',\n",
       " 573: 'aliquis_',\n",
       " 574: 'ai_',\n",
       " 575: 'arg_',\n",
       " 576: 'manus_',\n",
       " 577: 'sententia_',\n",
       " 578: 'dig_',\n",
       " 579: 'dedit_',\n",
       " 580: '29_',\n",
       " 581: 'sis_',\n",
       " 582: 'ores_',\n",
       " 583: 'uti_',\n",
       " 584: 'christum_',\n",
       " 585: 'tuum_',\n",
       " 586: 'malum_',\n",
       " 587: 'dici_',\n",
       " 588: 'causam_',\n",
       " 589: 'meum_',\n",
       " 590: 'runt_',\n",
       " 591: 'aliter_',\n",
       " 592: 'mo_',\n",
       " 593: 'venit_',\n",
       " 594: 'necesse_',\n",
       " 595: 'olim_',\n",
       " 596: 'nte_',\n",
       " 597: 'multis_',\n",
       " 598: 'tate_',\n",
       " 599: 'finem_',\n",
       " 600: 'isse_',\n",
       " 601: 'naturae_',\n",
       " 602: 'factus_',\n",
       " 603: 'iterum_',\n",
       " 604: 'are_',\n",
       " 605: 'lege_',\n",
       " 606: 'naturam_',\n",
       " 607: 'manu_',\n",
       " 608: 'actus_',\n",
       " 609: 'matth_',\n",
       " 610: 'diem_',\n",
       " 611: 'gratiam_',\n",
       " 612: 'regis_',\n",
       " 613: 'praeter_',\n",
       " 614: 'posset_',\n",
       " 615: 'tibus_',\n",
       " 616: 'oratio_',\n",
       " 617: 'nda_',\n",
       " 618: 'ge_',\n",
       " 619: '$_',\n",
       " 620: 'certe_',\n",
       " 621: 'pr_',\n",
       " 622: 'mortuus_',\n",
       " 623: 'omnem_',\n",
       " 624: 'tui_',\n",
       " 625: 'eft_',\n",
       " 626: 'fide_',\n",
       " 627: 'iu_',\n",
       " 628: '^&_',\n",
       " 629: '%_',\n",
       " 630: 'incolarum_',\n",
       " 631: '_',\n",
       " 632: 'denique_',\n",
       " 633: 'annis_',\n",
       " 634: 'alios_',\n",
       " 635: 'ura_',\n",
       " 636: 'filio_',\n",
       " 637: 'mundi_',\n",
       " 638: 'suos_',\n",
       " 639: 'fere_',\n",
       " 640: 'adeo_',\n",
       " 641: 'patrem_',\n",
       " 642: 'quin_',\n",
       " 643: 'rom_',\n",
       " 644: 'vera_',\n",
       " 645: 'bo_',\n",
       " 646: 'virtus_',\n",
       " 647: 'regnum_',\n",
       " 648: 'cm_',\n",
       " 649: 'lem_',\n",
       " 650: 'bellum_',\n",
       " 651: 'libro_',\n",
       " 652: 'lum_',\n",
       " 653: 'ionis_',\n",
       " 654: 'tatem_',\n",
       " 655: 'ipsis_',\n",
       " 656: 'populi_',\n",
       " 657: 'divina_',\n",
       " 658: 'commune_',\n",
       " 659: 'dis_',\n",
       " 660: 'alias_',\n",
       " 661: 'tota_',\n",
       " 662: 'tuam_',\n",
       " 663: 'ie_',\n",
       " 664: 'des_',\n",
       " 665: 'pertinet_',\n",
       " 666: 'huic_',\n",
       " 667: 'patre_',\n",
       " 668: 'dicunt_',\n",
       " 669: 'vide_',\n",
       " 670: 'quippe_',\n",
       " 671: 'va_',\n",
       " 672: 'vere_',\n",
       " 673: 'eas_',\n",
       " 674: 'tertio_',\n",
       " 675: 'fratres_',\n",
       " 676: 'iste_',\n",
       " 677: 'animo_',\n",
       " 678: 'en_',\n",
       " 679: 'psal_',\n",
       " 680: 'similiter_',\n",
       " 681: 'scriptum_',\n",
       " 682: 'by_',\n",
       " 683: 'sumus_',\n",
       " 684: 'nostris_',\n",
       " 685: 'locus_',\n",
       " 686: 'sanctus_',\n",
       " 687: 'tuo_',\n",
       " 688: 'genere_',\n",
       " 689: 'ensis_',\n",
       " 690: 'cis_',\n",
       " 691: 'hominibus_',\n",
       " 692: 'terrae_',\n",
       " 693: 'multi_',\n",
       " 694: 'liber_',\n",
       " 695: 'viri_',\n",
       " 696: 'verunt_',\n",
       " 697: 'dam_',\n",
       " 698: 'essent_',\n",
       " 699: 'postquam_',\n",
       " 700: 'potentia_',\n",
       " 701: 'statim_',\n",
       " 702: 'via_',\n",
       " 703: 'tanquam_',\n",
       " 704: 'mala_',\n",
       " 705: 'hodie_',\n",
       " 706: 'art_',\n",
       " 707: 'apostolus_',\n",
       " 708: 'mei_',\n",
       " 709: 'xii_',\n",
       " 710: 'annos_',\n",
       " 711: 'potuit_',\n",
       " 712: 'iae_',\n",
       " 713: 'fuerunt_',\n",
       " 714: 'domus_',\n",
       " 715: 'ora_',\n",
       " 716: 'uni_',\n",
       " 717: 'illos_',\n",
       " 718: 'medio_',\n",
       " 719: 'lingua_',\n",
       " 720: 'nostrum_',\n",
       " 721: 'gloria_',\n",
       " 722: 'animae_',\n",
       " 723: '31_',\n",
       " 724: 'orem_',\n",
       " 725: 'multo_',\n",
       " 726: 'animi_',\n",
       " 727: 'sane_',\n",
       " 728: 'primus_',\n",
       " 729: 'animam_',\n",
       " 730: 'annum_',\n",
       " 731: 'fe_',\n",
       " 732: 'ntibus_',\n",
       " 733: 'bantur_',\n",
       " 734: 'aliquo_',\n",
       " 735: 'dat_',\n",
       " 736: 'materia_',\n",
       " 737: 'dicat_',\n",
       " 738: 'verbo_',\n",
       " 739: 'dicta_',\n",
       " 740: 'ar_',\n",
       " 741: 'anni_',\n",
       " 742: 'vult_',\n",
       " 743: 'usus_',\n",
       " 744: '<_',\n",
       " 745: 'meo_',\n",
       " 746: 'isti_',\n",
       " 747: 'ntem_',\n",
       " 748: 'vers_',\n",
       " 749: 'boni_',\n",
       " 750: 'nostro_',\n",
       " 751: 'etsi_',\n",
       " 752: 'xv_',\n",
       " 753: 'noster_',\n",
       " 754: 'rit_',\n",
       " 755: 'populo_',\n",
       " 756: 'dicuntur_',\n",
       " 757: 'episcopus_',\n",
       " 758: 'locis_',\n",
       " 759: 'species_',\n",
       " 760: 'urbe_',\n",
       " 761: 'aliquando_',\n",
       " 762: 'legem_',\n",
       " 763: 'temporis_',\n",
       " 764: 'ipsam_',\n",
       " 765: 'infra_',\n",
       " 766: 'nomina_',\n",
       " 767: 'meam_',\n",
       " 768: 'haud_',\n",
       " 769: 'numero_',\n",
       " 770: 'spiritu_',\n",
       " 771: 'mox_',\n",
       " 772: 'lex_',\n",
       " 773: 'facile_',\n",
       " 774: 'fides_',\n",
       " 775: 'spiritum_',\n",
       " 776: 'lia_',\n",
       " 777: 'male_',\n",
       " 778: 'talis_',\n",
       " 779: 'virtute_',\n",
       " 780: 'digitized_',\n",
       " 781: 'israel_',\n",
       " 782: 'juxta_',\n",
       " 783: 'provincia_',\n",
       " 784: '..._',\n",
       " 785: 'huiusmodi_',\n",
       " 786: 'ones_',\n",
       " 787: 'entur_',\n",
       " 788: 'fuerat_',\n",
       " 789: 'urbem_',\n",
       " 790: '33_',\n",
       " 791: 'and_',\n",
       " 792: 'aqua_',\n",
       " 793: 'eris_',\n",
       " 794: 'dico_',\n",
       " 795: 'alius_',\n",
       " 796: 'corde_',\n",
       " 797: 'minime_',\n",
       " 798: 'domum_',\n",
       " 799: 'tanta_',\n",
       " 800: '35_',\n",
       " 801: 'tatis_',\n",
       " 802: 'tionem_',\n",
       " 803: 'nullo_',\n",
       " 804: 'cs_',\n",
       " 805: 'dem_',\n",
       " 806: 'veritate_',\n",
       " 807: 'tia_',\n",
       " 808: 'regem_',\n",
       " 809: 'longe_',\n",
       " 810: 'meus_',\n",
       " 811: 'oris_',\n",
       " 812: 'tot_',\n",
       " 813: '.._',\n",
       " 814: 'tertium_',\n",
       " 815: 'bello_',\n",
       " 816: 'ecclesiam_',\n",
       " 817: 'intellectus_',\n",
       " 818: 'tanto_',\n",
       " 819: 'melius_',\n",
       " 820: 'joa_',\n",
       " 821: 'unius_',\n",
       " 822: 'ot_',\n",
       " 823: 'alterum_',\n",
       " 824: 'legis_',\n",
       " 825: 'ov_',\n",
       " 826: 'romani_',\n",
       " 827: 'extra_',\n",
       " 828: 'adversus_',\n",
       " 829: 'bonis_',\n",
       " 830: 'habeat_',\n",
       " 831: 'int_',\n",
       " 832: 'ani_',\n",
       " 833: 'corpora_',\n",
       " 834: 'par_',\n",
       " 835: '40_',\n",
       " 836: 'iter_',\n",
       " 837: 'tamquam_',\n",
       " 838: 'ari_',\n",
       " 839: 'italia_',\n",
       " 840: 'ordine_',\n",
       " 841: 'ibid_',\n",
       " 842: 'unam_',\n",
       " 843: 'quatuor_',\n",
       " 844: 'ntis_',\n",
       " 845: 'formam_',\n",
       " 846: 'sola_',\n",
       " 847: 'urbis_',\n",
       " 848: 'lus_',\n",
       " 849: 'summa_',\n",
       " 850: 'mare_',\n",
       " 851: 'significat_',\n",
       " 852: '32_',\n",
       " 853: 'sententiam_',\n",
       " 854: 'persona_',\n",
       " 855: 'tribus_',\n",
       " 856: 'tuis_',\n",
       " 857: 'xiv_',\n",
       " 858: 'vix_',\n",
       " 859: 'sancto_',\n",
       " 860: 'quidquid_',\n",
       " 861: 'xit_',\n",
       " 862: 'amplius_',\n",
       " 863: 'mentis_',\n",
       " 864: 'peccata_',\n",
       " 865: 'populus_',\n",
       " 866: 'morte_',\n",
       " 867: '34_',\n",
       " 868: 'ha_',\n",
       " 869: 'loquitur_',\n",
       " 870: 'tandem_',\n",
       " 871: 'plures_',\n",
       " 872: 'alis_',\n",
       " 873: 'nondum_',\n",
       " 874: 'sus_',\n",
       " 875: 'ordinem_',\n",
       " 876: 'iure_',\n",
       " 877: 'bitur_',\n",
       " 878: 'tos_',\n",
       " 879: 'quanto_',\n",
       " 880: 'habuit_',\n",
       " 881: 'rat_',\n",
       " 882: 'generis_',\n",
       " 883: 'multum_',\n",
       " 884: 'ua_',\n",
       " 885: 'malo_',\n",
       " 886: 'vox_',\n",
       " 887: 'paulus_',\n",
       " 888: 'augustinus_',\n",
       " 889: 'cura_',\n",
       " 890: 'sensus_',\n",
       " 891: 'toto_',\n",
       " 892: 'utique_',\n",
       " 893: 'paulo_',\n",
       " 894: 'bono_',\n",
       " 895: 'coram_',\n",
       " 896: 'tuae_',\n",
       " 897: 'gloriam_',\n",
       " 898: 'alium_',\n",
       " 899: 'altera_',\n",
       " 900: 'nullus_',\n",
       " 901: 'intra_',\n",
       " 902: 'diebus_',\n",
       " 903: 'solus_',\n",
       " 904: 'nullum_',\n",
       " 905: 'principium_',\n",
       " 906: 'cus_',\n",
       " 907: 'dit_',\n",
       " 908: 'libri_',\n",
       " 909: 'ponit_',\n",
       " 910: 'ria_',\n",
       " 911: 'nostrae_',\n",
       " 912: 'nunquam_',\n",
       " 913: 'ps_',\n",
       " 914: 'codd_',\n",
       " 915: 'arma_',\n",
       " 916: 'diu_',\n",
       " 917: 'velut_',\n",
       " 918: 'auctoritate_',\n",
       " 919: 'fine_',\n",
       " 920: 'quamquam_',\n",
       " 921: 'dare_',\n",
       " 922: 'atis_',\n",
       " 923: '36_',\n",
       " 924: 'sanctum_',\n",
       " 925: 'set_',\n",
       " 926: 'suas_',\n",
       " 927: 'fiat_',\n",
       " 928: '50_',\n",
       " 929: 'peccato_',\n",
       " 930: 'namque_',\n",
       " 931: 'xiii_',\n",
       " 932: 'constat_',\n",
       " 933: 'vim_',\n",
       " 934: 'quinque_',\n",
       " 935: 'secunda_',\n",
       " 936: 'salutem_',\n",
       " 937: 'dicimus_',\n",
       " 938: 'propria_',\n",
       " 939: 'ignis_',\n",
       " 940: 'media_',\n",
       " 941: 'amus_',\n",
       " 942: 'pag_',\n",
       " 943: 'tae_',\n",
       " 944: 'vestra_',\n",
       " 945: 'tria_',\n",
       " 946: '}_',\n",
       " 947: 'fuerint_',\n",
       " 948: 'mortis_',\n",
       " 949: 'duas_',\n",
       " 950: 'regni_',\n",
       " 951: 'verit_',\n",
       " 952: 'duobus_',\n",
       " 953: 'ebat_',\n",
       " 954: 'hos_',\n",
       " 955: 'proprie_',\n",
       " 956: 'ali_',\n",
       " 957: 'habebat_',\n",
       " 958: 'virtutem_',\n",
       " 959: 'mm_',\n",
       " 960: 'dus_',\n",
       " 961: 'homine_',\n",
       " 962: 'ira_',\n",
       " 963: 'finis_',\n",
       " 964: 'david_',\n",
       " 965: 'pe_',\n",
       " 966: 'ini_',\n",
       " 967: 'actu_',\n",
       " 968: '_',\n",
       " 969: 'lam_',\n",
       " 970: 'tor_',\n",
       " 971: 'porro_',\n",
       " 972: 'populum_',\n",
       " 973: 'gentes_',\n",
       " 974: 'numquam_',\n",
       " 975: 'data_',\n",
       " 976: 'atus_',\n",
       " 977: 'be_',\n",
       " 978: 'dc_',\n",
       " 979: 'magno_',\n",
       " 980: 'civitatis_',\n",
       " 981: 'ata_',\n",
       " 982: 'carnis_',\n",
       " 983: 'dixi_',\n",
       " 984: 'alterius_',\n",
       " 985: 'oculos_',\n",
       " 986: 'totius_',\n",
       " 987: 'eret_',\n",
       " 988: 'saeculo_',\n",
       " 989: 'more_',\n",
       " 990: 'oppidum_',\n",
       " 991: 'rus_',\n",
       " 992: 'rentur_',\n",
       " 993: 'petrus_',\n",
       " 994: 'potestatem_',\n",
       " 995: 'litteris_',\n",
       " 996: 'donec_',\n",
       " 997: 'accepit_',\n",
       " 998: 'romae_',\n",
       " 999: 'versus_',\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.reverseVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a578452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:42:30.076661Z",
     "iopub.status.busy": "2023-03-26T00:42:30.075943Z",
     "iopub.status.idle": "2023-03-26T00:42:30.082327Z",
     "shell.execute_reply": "2023-03-26T00:42:30.081744Z",
     "shell.execute_reply.started": "2023-03-26T00:42:30.076635Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return [tokenizer.convert_tokens_to_ids(sent) for sent in batch]\n",
    "\n",
    "def untokenize_batch(batch):\n",
    "    results = []\n",
    "    for sent in batch:\n",
    "        tmp_sent = []\n",
    "        for word in sent:\n",
    "            predicted_word=\"%s%s\" % (tokenizer.reverseVocab[word], \"\")\n",
    "            predicted_word=re.sub(\"_$\", \"\", predicted_word).lower()\n",
    "            tmp_sent.append(predicted_word)\n",
    "        results.append(tmp_sent)\n",
    "    #return [tokenizer.convert_ids_to_tokens(sent) for sent in batch]\n",
    "    return results\n",
    "\n",
    "def detokenize(sent):\n",
    "    \"\"\" Roughly detokenizes (mainly undoes wordpiece) \"\"\"\n",
    "    new_sent = []\n",
    "    for i, tok in enumerate(sent):\n",
    "        if tok.startswith(\"##\"):\n",
    "            new_sent[len(new_sent) - 1] = new_sent[len(new_sent) - 1] + tok[2:]\n",
    "        else:\n",
    "            new_sent.append(tok)\n",
    "    return new_sent\n",
    "\n",
    "CLS = '[CLS]'\n",
    "SEP = '[SEP]'\n",
    "MASK = '[MASK]'\n",
    "mask_id = tokenizer.convert_tokens_to_ids([MASK])[0]\n",
    "sep_id = tokenizer.convert_tokens_to_ids([SEP])[0]\n",
    "cls_id = tokenizer.convert_tokens_to_ids([CLS])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f89075dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:42:40.130082Z",
     "iopub.status.busy": "2023-03-26T00:42:40.129405Z",
     "iopub.status.idle": "2023-03-26T00:42:40.134310Z",
     "shell.execute_reply": "2023-03-26T00:42:40.133845Z",
     "shell.execute_reply.started": "2023-03-26T00:42:40.130057Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_step(out, gen_idx, temperature=None, top_k=0, sample=False, return_list=True):\n",
    "    \"\"\" Generate a word from from out[gen_idx]\n",
    "    \n",
    "    args:\n",
    "        - out (torch.Tensor): tensor of logits of size batch_size x seq_len x vocab_size\n",
    "        - gen_idx (int): location for which to generate for\n",
    "        - top_k (int): if >0, only sample from the top k most probable words\n",
    "        - sample (Bool): if True, sample from full distribution. Overridden by top_k \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    logits = out[\"logits\"][:, gen_idx]\n",
    "    if temperature is not None:\n",
    "        logits = logits / temperature\n",
    "    if top_k > 0:\n",
    "        kth_vals, kth_idx = logits.topk(top_k, dim=-1)\n",
    "        dist = torch.distributions.categorical.Categorical(logits=kth_vals)\n",
    "        idx = kth_idx.gather(dim=1, index=dist.sample().unsqueeze(-1)).squeeze(-1)\n",
    "    elif sample:\n",
    "        dist = torch.distributions.categorical.Categorical(logits=logits)\n",
    "        idx = dist.sample().squeeze(-1)\n",
    "    else:\n",
    "        idx = torch.argmax(logits, dim=-1)\n",
    "    return idx.tolist() if return_list else idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9f31bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:42:41.749634Z",
     "iopub.status.busy": "2023-03-26T00:42:41.748881Z",
     "iopub.status.idle": "2023-03-26T00:42:41.765860Z",
     "shell.execute_reply": "2023-03-26T00:42:41.765348Z",
     "shell.execute_reply.started": "2023-03-26T00:42:41.749609Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generation modes as functions\n",
    "import math\n",
    "import time\n",
    "from LatinBERT.predict_words import proc\n",
    "\n",
    "def get_init_text(seed_text, max_len, batch_size = 1, rand_init=False):\n",
    "    \"\"\" Get initial sentence by padding seed_text with either masks or random words to max_len \"\"\"\n",
    "    batch = [seed_text + [MASK] * max_len + [SEP] for _ in range(batch_size)]\n",
    "    #if rand_init:\n",
    "    #    for ii in range(max_len):\n",
    "    #        init_idx[seed_len+ii] = np.random.randint(0, len(tokenizer.vocab))\n",
    "    \n",
    "    return tokenize_batch(batch)\n",
    "\n",
    "def parallel_sequential_generation(seed_text, max_len=15, top_k=0, temperature=None, max_iter=300, burnin=200,\n",
    "                                   cuda=False, print_every=10, verbose=True):\n",
    "    \"\"\" Generate for one random position at a timestep\n",
    "    \n",
    "    args:\n",
    "        - burnin: during burn-in period, sample from full distribution; afterwards take argmax\n",
    "    \"\"\"\n",
    "    seed_len = len(seed_text)\n",
    "    batch = get_init_text(seed_text, max_len, batch_size)\n",
    "    \n",
    "    for ii in range(max_iter):\n",
    "        kk = np.random.randint(0, max_len)\n",
    "        for jj in range(batch_size):\n",
    "            batch[jj][seed_len+kk] = mask_id\n",
    "        inp = torch.tensor(batch).cuda() if cuda else torch.tensor(batch)\n",
    "        out = model(inp)\n",
    "        topk = top_k if (ii >= burnin) else 0\n",
    "        idxs = generate_step(out, gen_idx=seed_len+kk, top_k=topk, temperature=temperature, sample=(ii < burnin))\n",
    "        for jj in range(batch_size):\n",
    "            batch[jj][seed_len+kk] = idxs[jj]\n",
    "            \n",
    "        if verbose and np.mod(ii+1, print_every) == 0:\n",
    "            for_print = tokenizer.convert_ids_to_tokens(batch[0])\n",
    "            for_print = for_print[:seed_len+kk+1] + ['(*)'] + for_print[seed_len+kk+1:]\n",
    "            print(\"iter\", ii+1, \" \".join(for_print))\n",
    "            \n",
    "    return untokenize_batch(batch)\n",
    "\n",
    "def parallel_generation(seed_text, max_len=15, top_k=0, temperature=None, max_iter=300, sample=True, \n",
    "                        cuda=False, print_every=10, verbose=True):\n",
    "    \"\"\" Generate for all positions at a time step \"\"\"\n",
    "    seed_len = len(seed_text)\n",
    "    batch = get_init_text(seed_text, max_len, batch_size)\n",
    "    \n",
    "    for ii in range(max_iter):\n",
    "        inp = torch.tensor(batch).cuda() if cuda else torch.tensor(batch)\n",
    "        out = model(inp)\n",
    "        for kk in range(max_len):\n",
    "            idxs = generate_step(out, gen_idx=seed_len+kk, top_k=top_k, temperature=temperature, sample=sample)\n",
    "            for jj in range(batch_size):\n",
    "                batch[jj][seed_len+kk] = idxs[jj]\n",
    "            \n",
    "        if verbose and np.mod(ii, print_every) == 0:\n",
    "            print(\"iter\", ii+1, \" \".join(tokenizer.convert_ids_to_tokens(batch[0])))\n",
    "    \n",
    "    return untokenize_batch(batch)\n",
    "            \n",
    "def sequential_generation(seed_text, batch_size=2, max_len=15, leed_out_len=15, \n",
    "                          top_k=0, temperature=None, sample=True, cuda=False):\n",
    "    \"\"\" Generate one word at a time, in L->R order \"\"\"\n",
    "    seed_len = len(seed_text)\n",
    "    batch = get_init_text(seed_text, max_len, batch_size)\n",
    "    batch = batch.cuda() if cuda else batch\n",
    "    \n",
    "    for ii in range(max_len):\n",
    "        inp = [sent[:seed_len+ii+leed_out_len]+[sep_id] for sent in batch]\n",
    "        inp = torch.tensor(batch).cuda() if cuda else torch.tensor(batch)\n",
    "        out = model(inp)\n",
    "        idxs = generate_step(out, gen_idx=seed_len+ii, top_k=top_k, temperature=temperature, sample=sample)\n",
    "        for jj in range(batch_size):\n",
    "            batch[jj][seed_len+ii] = idxs[jj]\n",
    "        \n",
    "        return untokenize_batch(batch)\n",
    "\n",
    "\n",
    "def generate(n_samples, tokenizer, seed_text=\"[CLS]\", batch_size=10, max_len=25, \n",
    "             sample=True, top_k=100, temperature=1.0, burnin=200, max_iter=500,\n",
    "             cuda=False, print_every=1):\n",
    "    # main generation function to call\n",
    "    sentences = []\n",
    "    n_batches = math.ceil(n_samples / batch_size)\n",
    "    start_time = time.time()\n",
    "    for batch_n in range(n_batches):\n",
    "        batch = parallel_sequential_generation(seed_text, max_len=max_len, top_k=top_k,\n",
    "                                               temperature=temperature, burnin=burnin, max_iter=max_iter, \n",
    "                                               cuda=cuda, verbose=False)\n",
    "        \n",
    "        #batch = sequential_generation(seed_text, batch_size=20, max_len=max_len, top_k=top_k, temperature=temperature, leed_out_len=leed_out_len, sample=sample)\n",
    "        #batch = parallel_generation(seed_text, max_len=max_len, top_k=top_k, temperature=temperature, sample=sample, max_iter=max_iter)\n",
    "        print(batch)\n",
    "        if (batch_n + 1) % print_every == 0:\n",
    "            print(\"Finished batch %d in %.3fs\" % (batch_n + 1, time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "        \n",
    "        sentences += batch\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d489cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:42:44.418849Z",
     "iopub.status.busy": "2023-03-26T00:42:44.418162Z",
     "iopub.status.idle": "2023-03-26T00:42:44.423138Z",
     "shell.execute_reply": "2023-03-26T00:42:44.422661Z",
     "shell.execute_reply.started": "2023-03-26T00:42:44.418820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def printer(sent, should_detokenize=True):\n",
    "    if should_detokenize:\n",
    "        sent = detokenize(sent)[1:-1]\n",
    "    print(\" \".join(sent))\n",
    "    \n",
    "def read_sents(in_file, should_detokenize=False):\n",
    "    sents = [sent.strip().split() for sent in open(in_file).readlines()]\n",
    "    if should_detokenize:\n",
    "        sents = [detokenize(sent) for sent in sents]\n",
    "    return sents\n",
    "\n",
    "def write_sents(out_file, sents, should_detokenize=False):\n",
    "    with open(out_file, \"w\") as out_fh:\n",
    "        for sent in sents:\n",
    "            sent = detokenize(sent[1:-1]) if should_detokenize else sent\n",
    "            out_fh.write(\"%s\\n\" % \" \".join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47c52fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:42:45.829019Z",
     "iopub.status.busy": "2023-03-26T00:42:45.828310Z",
     "iopub.status.idle": "2023-03-26T00:42:54.016572Z",
     "shell.execute_reply": "2023-03-26T00:42:54.015989Z",
     "shell.execute_reply.started": "2023-03-26T00:42:45.828975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[cls]', 'init', '', '.', 'init', '', '.', 'praemi', 'tte', 'bd', 'm', '-', 'ne', 's', '.', 'congr', '', '.', ':', '(', '1', ')', 'aa', '.', 'de', 'matr', '', '.', '1', '.', 'et', '2', '.', 'de', 'matrimonio', 'toro', '', 'conco', 'mita', 'nte', '.', '[sep]'], ['[cls]', 'eme', '', 'eft', 'o', 'eme', '', 'efte', '', ':', 'eft', 'o', 'eme', '', 'efte', '', 'e', '', '', '', '', '', '', '', '', '', '', ':', 'eft', 'o', 'eme', '', '-', 'efte', '', 'e', '', '', '', '', '.', '[sep]'], ['[cls]', 'apo', 'phi', 'terat', 'orum', '.', 'apo', 'phi', 'terat', 'orum', '.', 'asc', '', 'aga', 'neus', '', '.', 'asc', '', 'aga', 'nus', '.', 'aga', 'neus', '', '.', 'aga', 'nus', '.', 'alc', 'ani', 'us', '.', 'aga', '', '-', 'ne', '.', 'aga', 'nus', '.', '[sep]'], ['[cls]', '16', 'pr', '.', 'modesti', 'nus', 'de', 'demi', '', '-', 'ne', '.', '1', 'uiui', 'tian', 'a', ']', 'uiui', 'tian', 'a', 'u', ',', 'ue', 'xta', 'f', '^', ',', 'ue', 'xta', '(', 'uiui', 'tian', 'a', 'f', ')', 'u', 'uiui', 'tian', 'a', '.', '.', '[sep]'], ['[cls]', 'succes', '', 'sori', '', 'succedere', '', 'necesse', 'est', ',', '', '', '', '', '5', 'n', '^', 'n', '^', 'n', '^', 'nts', '', '^', 'n', '^', 'n', '^', 'n', '^', 'n', '^', 'n', '^', 'sin', '.', 'v', 'c', '.', 'ii', '.', '[sep]'], ['[cls]', 'membr', '', '.', 'hau', '', 'membr', '', 'hau', '', 'partis', '.', 'hau', '', '-', 'partis', '.', 'hau', '', 'partis', '.', 'hau', '', '-', 'partis', '.', 'hau', '', '-', 'que', 'membr', '', '.', 'membr', '', 'hau', '', '-', 'que', 'partis', '.', '[sep]'], ['[cls]', '1', '.', 'et', '2', '.', '8e', 'rv', 'et', 'q', '.', 'd', '.', '8e', 'rv', 'et', 'q', '.', '1', '.', 'q', '.', 'd', '.', 'et', 'i', '.', 'et', '2', '.', 'somni', 'et', 'q', '.', 'i', '.', 'et', 'q', '.', 'i', '.', '[sep]'], ['[cls]', 'itc', 'm', 'cum', 'vei', '&', 'apos', ';', 'um', 'aliquod', 'cum', 're', 'aliqua', 'compa', 'rur', '', ',', 'fcc', 'und', 'ura', 'ip', 'fei', '', '-', 'ne', 'qualit', 'atc', 'm', ',', 'auc', '', 'fimil', 'e', 'quid', ',', 'effici', 'uo', '-', 'ne', 'poteft', '.', '[sep]'], ['[cls]', 'c', 'eft', 'arator', '', 'l', '.', 'anni', 'i', 'c', 'c', 'ett', 'l', '.', 'anni', 'i', 'c', 'eft', 'arator', '', 'l', '.', 'anni', 'i', 'c', 'cft', 'arator', '', 'l', '.', 'anni', 'i', 'c', 'eil', '', 'arator', '', 'l', '.', 'an', '.', '[sep]'], ['[cls]', '.', 'l', '.', 'f', '.', '2', 't', '.', 'p', '.', 'c', '.', '1', '.', 'a', '.', 'b', '.', 's', '.', '4', '-', 'ne', '.', '.', '.', '1', '.', 'd', '.', 'f', '.', '2', 't', '.', 'p', '-.', '', '4', '.', '[sep]']]\n",
      "Finished batch 1 in 8.173s\n"
     ]
    }
   ],
   "source": [
    "n_samples = 1\n",
    "batch_size = 10\n",
    "max_len = 40\n",
    "top_k = 100\n",
    "temperature = 0.7\n",
    "\n",
    "leed_out_len = 5 # max_len\n",
    "burnin = 250\n",
    "sample = True\n",
    "max_iter = 500\n",
    "\n",
    "# Choose the prefix context\n",
    "seed_text = \"[CLS]\".split()\n",
    "\n",
    "for temp in [1.0]:\n",
    "    bert_sents = generate(n_samples, tokenizer, seed_text=seed_text, batch_size=batch_size, max_len=max_len,\n",
    "                          sample=sample, top_k=top_k, temperature=temperature, burnin=burnin, max_iter=max_iter,\n",
    "                          cuda=True)\n",
    "    out_file = \"Results/len%d-burnin%d-topk%d-temp4%.3f.txt\" % (max_len, burnin, top_k, temp)\n",
    "    write_sents(out_file, bert_sents, should_detokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a72abf-9a1c-4485-ae2a-5dd6f89fb107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T00:01:10.871708Z",
     "iopub.status.busy": "2023-03-26T00:01:10.871051Z",
     "iopub.status.idle": "2023-03-26T00:01:10.885840Z",
     "shell.execute_reply": "2023-03-26T00:01:10.885082Z",
     "shell.execute_reply.started": "2023-03-26T00:01:10.871684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pedicabo ego vos et irrumabo Aureli pathice et cinaede Furi, qui me ex versiculss meis putastis quod sunt molliculi, parum pudicum. Nam castum esse decet pium poetam ipsum, versiculos nihil necesse est qui tum denique habent salem ac leporem Si sint mollicul ac parum pudici et quod pruriat incitre possint , ut'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(tokenizer, \"Pedicabo ego vos et irrumabo Aureli pathice et cinaede Furi, qui me ex versiculss meis putastis quod sunt molliculi, parum pudicum. Nam castum esse decet pium poetam ipsum, versiculos nihil necesse est qui tum denique habent salem ac leporem Si sint mollicul ac parum pudici et quod pruriat incitre possint ,\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0d51bcd-ee20-44b3-9f03-6445d93fba01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T01:43:22.621446Z",
     "iopub.status.busy": "2023-03-26T01:43:22.621154Z",
     "iopub.status.idle": "2023-03-26T01:43:22.942656Z",
     "shell.execute_reply": "2023-03-26T01:43:22.942101Z",
     "shell.execute_reply.started": "2023-03-26T01:43:22.621426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rufus faciendi et formaliter dici posse sens, ut [ b + j [ bc / , aut ita uti aliquem aliquem ad alia similia : quo minus id efficere aliquis possit ; et ita facere aliquem alicujus ope . vel vel aliquid alicujus vel aliquod eorum vel ea qua ad illa\n"
     ]
    }
   ],
   "source": [
    "context = \"rufus\"\n",
    "for i in range(50):\n",
    "    context = predict(tokenizer, context, model, sampleK=True)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8b36374-95e9-4464-96a6-9f84a03bda82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T01:43:10.544590Z",
     "iopub.status.busy": "2023-03-26T01:43:10.543950Z",
     "iopub.status.idle": "2023-03-26T01:43:10.560676Z",
     "shell.execute_reply": "2023-03-26T01:43:10.560155Z",
     "shell.execute_reply.started": "2023-03-26T01:43:10.544568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arma in'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(tokenizer, \"Arma\", model, sampleK=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a93b53f2-c10f-48c0-b41c-dcfa5e3f7464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T01:41:45.013687Z",
     "iopub.status.busy": "2023-03-26T01:41:45.013429Z",
     "iopub.status.idle": "2023-03-26T01:41:45.032595Z",
     "shell.execute_reply": "2023-03-26T01:41:45.032115Z",
     "shell.execute_reply.started": "2023-03-26T01:41:45.013669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arma virumque cano, Troiae qui primus ab oris Italiam, fato profugus, Laviniaque venit litora, multum ille et terris iactatus et alto vi superum saevae memorem iunonis ob iram; multa quoque et bello passus, dum conderet urbem,'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infilling(tokenizer, \"Arma virumque cano, Troiae qui primus ab oris Italiam, fato profugus, Laviniaque venit litora, multum ille et terris iactatus et alto vi superum saevae memorem\", \"ob iram; multa quoque et bello passus, dum conderet urbem,\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091efdac-6770-47a0-8951-0cd6c5dc3b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
