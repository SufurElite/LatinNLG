{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3800424-0d4c-4ca8-becd-5c0625df43da",
   "metadata": {},
   "source": [
    "# Latin Transformer\n",
    "This notebook works through the creation of a character transformer model but done for my custom Latin Corpus that I've created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbbceb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T18:07:28.073353Z",
     "iopub.status.busy": "2023-03-25T18:07:28.072765Z",
     "iopub.status.idle": "2023-03-25T18:08:18.380970Z",
     "shell.execute_reply": "2023-03-25T18:08:18.379688Z",
     "shell.execute_reply.started": "2023-03-25T18:07:28.073328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the existing corpus\n",
      "abbofloracensis had 1 pieces of work with a total of 34398 characters of text\n",
      "abelard had 1 pieces of work with a total of 15483 characters of text\n",
      "acticussincerius had 1 pieces of work with a total of 5947 characters of text\n",
      "addison had 1 pieces of work with a total of 3074 characters of text\n",
      "adso had 1 pieces of work with a total of 13551 characters of text\n",
      "aelredus had 1 pieces of work with a total of 118173 characters of text\n",
      "agnes had 1 pieces of work with a total of 74784 characters of text\n",
      "alanus had 1 pieces of work with a total of 136527 characters of text\n",
      "albericodamarcellise had 1 pieces of work with a total of 172 characters of text\n",
      "albertanus had 1 pieces of work with a total of 108213 characters of text\n",
      "albertofaix had 1 pieces of work with a total of 51703 characters of text\n",
      "alcuin had 1 pieces of work with a total of 1641 characters of text\n",
      "aleandrogerolamo had 1 pieces of work with a total of 10197 characters of text\n",
      "alfonsi had 1 pieces of work with a total of 105630 characters of text\n",
      "ambrose had 1 pieces of work with a total of 15147 characters of text\n",
      "ammianus had 18 pieces of work with a total of 975460 characters of text\n",
      "ampelius had 1 pieces of work with a total of 52872 characters of text\n",
      "andecavis had 1 pieces of work with a total of 920 characters of text\n",
      "andreasbergoma had 1 pieces of work with a total of 28522 characters of text\n",
      "andronicus had 1 pieces of work with a total of 2238 characters of text\n",
      "angeloambrogini had 1 pieces of work with a total of 6096 characters of text\n",
      "angelopoliziano had 1 pieces of work with a total of 2637 characters of text\n",
      "angilbert had 1 pieces of work with a total of 2094 characters of text\n",
      "annalesregnifrancorum had 1 pieces of work with a total of 155834 characters of text\n",
      "annalesvedastini had 1 pieces of work with a total of 54567 characters of text\n",
      "anon had 1 pieces of work with a total of 793 characters of text\n",
      "anonymous had 1 pieces of work with a total of 6463 characters of text\n",
      "anselmepistula had 1 pieces of work with a total of 5009 characters of text\n",
      "anselmproslogion had 1 pieces of work with a total of 39144 characters of text\n",
      "apicius had 1 pieces of work with a total of 8603 characters of text\n",
      "appverg had 1 pieces of work with a total of 8895 characters of text\n",
      "appvergcomp had 1 pieces of work with a total of 110025 characters of text\n",
      "appvergculex had 1 pieces of work with a total of 18887 characters of text\n",
      "apuleius had 13 pieces of work with a total of 604335 characters of text\n",
      "aquinas had 1 pieces of work with a total of 33728 characters of text\n",
      "arbroath had 1 pieces of work with a total of 7497 characters of text\n",
      "archpoet had 1 pieces of work with a total of 29641 characters of text\n",
      "aristotle had 1 pieces of work with a total of 11537 characters of text\n",
      "arnobius had 1 pieces of work with a total of 66612 characters of text\n",
      "arnulf had 1 pieces of work with a total of 1387 characters of text\n",
      "asconius had 1 pieces of work with a total of 112203 characters of text\n",
      "asserius had 1 pieces of work with a total of 89247 characters of text\n",
      "augustine had 7 pieces of work with a total of 402151 characters of text\n",
      "aureliusvictor had 2 pieces of work with a total of 149735 characters of text\n",
      "aus had 1 pieces of work with a total of 2241 characters of text\n",
      "ausonius had 24 pieces of work with a total of 292442 characters of text\n",
      "ave had 1 pieces of work with a total of 6949 characters of text\n",
      "avianus had 1 pieces of work with a total of 30263 characters of text\n",
      "avienus had 1 pieces of work with a total of 27798 characters of text\n",
      "axio had 1 pieces of work with a total of 16543 characters of text\n",
      "bacon had 1 pieces of work with a total of 45816 characters of text\n",
      "balbus had 1 pieces of work with a total of 16073 characters of text\n",
      "balde had 1 pieces of work with a total of 765 characters of text\n",
      "baldo had 1 pieces of work with a total of 59162 characters of text\n",
      "bebel had 1 pieces of work with a total of 131504 characters of text\n",
      "bede had 5 pieces of work with a total of 575775 characters of text\n",
      "benedict had 1 pieces of work with a total of 92323 characters of text\n",
      "berengar had 1 pieces of work with a total of 37827 characters of text\n",
      "bernardcluny had 1 pieces of work with a total of 62164 characters of text\n",
      "bible had 1 pieces of work with a total of 91761 characters of text\n",
      "biggs had 1 pieces of work with a total of 44386 characters of text\n",
      "bill had 1 pieces of work with a total of 3236 characters of text\n",
      "blesensis had 1 pieces of work with a total of 51232 characters of text\n",
      "boethius had 10 pieces of work with a total of 263001 characters of text\n",
      "boethiusdacia had 1 pieces of work with a total of 50991 characters of text\n",
      "bonaventura had 1 pieces of work with a total of 72084 characters of text\n",
      "boskovic had 1 pieces of work with a total of 22752 characters of text\n",
      "brevechronicon had 1 pieces of work with a total of 8191 characters of text\n",
      "buchanan had 1 pieces of work with a total of 36240 characters of text\n",
      "bultelius had 1 pieces of work with a total of 2472 characters of text\n",
      "caeciliusbalbus had 1 pieces of work with a total of 45340 characters of text\n",
      "caesar had 11 pieces of work with a total of 616439 characters of text\n",
      "caesaraugustus had 1 pieces of work with a total of 18129 characters of text\n",
      "calpurniusflaccus had 1 pieces of work with a total of 48342 characters of text\n",
      "calpurniussiculus had 1 pieces of work with a total of 34152 characters of text\n",
      "campion had 1 pieces of work with a total of 13502 characters of text\n",
      "capellanus had 1 pieces of work with a total of 233924 characters of text\n",
      "carm had 1 pieces of work with a total of 1530 characters of text\n",
      "carmenarvale had 1 pieces of work with a total of 560 characters of text\n",
      "carmeninvictoriam had 1 pieces of work with a total of 13588 characters of text\n",
      "carmensaliare had 1 pieces of work with a total of 306 characters of text\n",
      "cassiodorus had 1 pieces of work with a total of 80306 characters of text\n",
      "catalogueliberien had 1 pieces of work with a total of 7213 characters of text\n",
      "cato had 1 pieces of work with a total of 14361 characters of text\n",
      "catullus had 1 pieces of work with a total of 85900 characters of text\n",
      "celsus had 8 pieces of work with a total of 696619 characters of text\n",
      "celtis had 1 pieces of work with a total of 1855 characters of text\n",
      "censorinus had 1 pieces of work with a total of 71644 characters of text\n",
      "cicero had 122 pieces of work with a total of 7438016 characters of text\n",
      "cinna had 1 pieces of work with a total of 861 characters of text\n",
      "claud had 1 pieces of work with a total of 4961 characters of text\n",
      "claudian had 19 pieces of work with a total of 441142 characters of text\n",
      "clitophon had 1 pieces of work with a total of 9925 characters of text\n",
      "colman had 1 pieces of work with a total of 1737 characters of text\n",
      "columba had 1 pieces of work with a total of 69044 characters of text\n",
      "columbus had 1 pieces of work with a total of 15591 characters of text\n",
      "columella had 9 pieces of work with a total of 562550 characters of text\n",
      "comes had 1 pieces of work with a total of 441 characters of text\n",
      "commodianus had 1 pieces of work with a total of 939 characters of text\n",
      "corippus had 8 pieces of work with a total of 217825 characters of text\n",
      "corneliopaoloamalteo had 1 pieces of work with a total of 503 characters of text\n",
      "corvinus had 1 pieces of work with a total of 4815 characters of text\n",
      "cotta had 1 pieces of work with a total of 12574 characters of text\n",
      "creeds had 1 pieces of work with a total of 6010 characters of text\n",
      "curtius had 1 pieces of work with a total of 51880 characters of text\n",
      "curtiusrufus had 8 pieces of work with a total of 536805 characters of text\n",
      "dante had 1 pieces of work with a total of 3188 characters of text\n",
      "dantealighieri had 1 pieces of work with a total of 120 characters of text\n",
      "dares had 1 pieces of work with a total of 56639 characters of text\n",
      "debury had 1 pieces of work with a total of 115993 characters of text\n",
      "declaratio had 1 pieces of work with a total of 10290 characters of text\n",
      "decretum had 1 pieces of work with a total of 15220 characters of text\n",
      "descartes had 1 pieces of work with a total of 5221 characters of text\n",
      "dicquid had 1 pieces of work with a total of 328 characters of text\n",
      "diesirae had 1 pieces of work with a total of 1430 characters of text\n",
      "diravi had 1 pieces of work with a total of 795 characters of text\n",
      "don had 1 pieces of work with a total of 29181 characters of text\n",
      "donation had 1 pieces of work with a total of 20027 characters of text\n",
      "dracontius had 16 pieces of work with a total of 266831 characters of text\n",
      "dumdiane had 1 pieces of work with a total of 1532 characters of text\n",
      "dumdomus had 1 pieces of work with a total of 349 characters of text\n",
      "ebulo had 1 pieces of work with a total of 73683 characters of text\n",
      "egeria had 1 pieces of work with a total of 53062 characters of text\n",
      "ein had 1 pieces of work with a total of 54962 characters of text\n",
      "enn had 1 pieces of work with a total of 8355 characters of text\n",
      "ennius had 1 pieces of work with a total of 25266 characters of text\n",
      "ennodius had 1 pieces of work with a total of 75591 characters of text\n",
      "ep had 1 pieces of work with a total of 18656 characters of text\n",
      "epistaustras had 1 pieces of work with a total of 34585 characters of text\n",
      "epitaphs had 1 pieces of work with a total of 10341 characters of text\n",
      "epitomecononiana had 1 pieces of work with a total of 39045 characters of text\n",
      "epitomefeliciana had 1 pieces of work with a total of 44673 characters of text\n",
      "erasmus had 1 pieces of work with a total of 177122 characters of text\n",
      "erchempert had 1 pieces of work with a total of 89824 characters of text\n",
      "estas had 1 pieces of work with a total of 597 characters of text\n",
      "eucherius had 1 pieces of work with a total of 28159 characters of text\n",
      "eugenius had 1 pieces of work with a total of 584 characters of text\n",
      "eugippius had 1 pieces of work with a total of 87808 characters of text\n",
      "eutropius had 1 pieces of work with a total of 133407 characters of text\n",
      "exivi had 1 pieces of work with a total of 30157 characters of text\n",
      "fabe had 1 pieces of work with a total of 31196 characters of text\n",
      "falcandus had 1 pieces of work with a total of 262882 characters of text\n",
      "falcone had 1 pieces of work with a total of 273400 characters of text\n",
      "faustoandrelino had 1 pieces of work with a total of 4769 characters of text\n",
      "ferraria had 1 pieces of work with a total of 18083 characters of text\n",
      "ficino had 1 pieces of work with a total of 20924 characters of text\n",
      "fletcher had 1 pieces of work with a total of 41616 characters of text\n",
      "florus had 1 pieces of work with a total of 188724 characters of text\n",
      "foedusaeternum had 1 pieces of work with a total of 3611 characters of text\n",
      "forsett had 1 pieces of work with a total of 33474 characters of text\n",
      "fortunat had 1 pieces of work with a total of 703 characters of text\n",
      "fragmentumlaurentianum had 1 pieces of work with a total of 6067 characters of text\n",
      "fredegarius had 1 pieces of work with a total of 168136 characters of text\n",
      "frodebertus had 1 pieces of work with a total of 6475 characters of text\n",
      "frontinus had 1 pieces of work with a total of 6813 characters of text\n",
      "fronto had 1 pieces of work with a total of 339779 characters of text\n",
      "fulbert had 1 pieces of work with a total of 760 characters of text\n",
      "fulgentius had 1 pieces of work with a total of 28596 characters of text\n",
      "gaius had 1 pieces of work with a total of 78184 characters of text\n",
      "galileo had 1 pieces of work with a total of 71985 characters of text\n",
      "garcilaso had 1 pieces of work with a total of 6652 characters of text\n",
      "garland had 1 pieces of work with a total of 21499 characters of text\n",
      "gaud had 1 pieces of work with a total of 811 characters of text\n",
      "gauss had 1 pieces of work with a total of 66500 characters of text\n",
      "gellius had 21 pieces of work with a total of 812717 characters of text\n",
      "germanicus had 1 pieces of work with a total of 33114 characters of text\n",
      "gestafrancorum had 1 pieces of work with a total of 8247 characters of text\n",
      "gestarom had 1 pieces of work with a total of 103434 characters of text\n",
      "gioacchino had 1 pieces of work with a total of 136901 characters of text\n",
      "girolamoaccelini had 1 pieces of work with a total of 3935 characters of text\n",
      "girolamoamaseo had 1 pieces of work with a total of 16479 characters of text\n",
      "glass had 1 pieces of work with a total of 190152 characters of text\n",
      "godfrey had 1 pieces of work with a total of 48392 characters of text\n",
      "grattius had 1 pieces of work with a total of 24829 characters of text\n",
      "gravissimas had 1 pieces of work with a total of 13221 characters of text\n",
      "greg had 1 pieces of work with a total of 5508 characters of text\n",
      "gregdecretals had 1 pieces of work with a total of 663928 characters of text\n",
      "gregory had 1 pieces of work with a total of 119429 characters of text\n",
      "gregorytours had 1 pieces of work with a total of 93341 characters of text\n",
      "gwinne had 1 pieces of work with a total of 23392 characters of text\n",
      "halley had 1 pieces of work with a total of 2243 characters of text\n",
      "hebet had 1 pieces of work with a total of 660 characters of text\n",
      "henry had 1 pieces of work with a total of 6543 characters of text\n",
      "henrysettimello had 1 pieces of work with a total of 42703 characters of text\n",
      "hipp had 1 pieces of work with a total of 13938 characters of text\n",
      "histapoll had 1 pieces of work with a total of 79949 characters of text\n",
      "histbrit had 1 pieces of work with a total of 64287 characters of text\n",
      "holberg had 1 pieces of work with a total of 208989 characters of text\n",
      "horace had 10 pieces of work with a total of 297826 characters of text\n",
      "hrabanus had 1 pieces of work with a total of 1155 characters of text\n",
      "hugo had 1 pieces of work with a total of 53280 characters of text\n",
      "hydatiuschronicon had 1 pieces of work with a total of 40888 characters of text\n",
      "hydatiusfasti had 1 pieces of work with a total of 45910 characters of text\n",
      "hyginus had 1 pieces of work with a total of 75886 characters of text\n",
      "hymni had 1 pieces of work with a total of 10922 characters of text\n",
      "iabervocius had 1 pieces of work with a total of 4204 characters of text\n",
      "iamdulcis had 1 pieces of work with a total of 1239 characters of text\n",
      "ilias had 1 pieces of work with a total of 47469 characters of text\n",
      "index had 1 pieces of work with a total of 1604 characters of text\n",
      "indices had 1 pieces of work with a total of 1860 characters of text\n",
      "innocent had 1 pieces of work with a total of 101995 characters of text\n",
      "inquisitio had 1 pieces of work with a total of 28586 characters of text\n",
      "inscriptions had 1 pieces of work with a total of 5249 characters of text\n",
      "iordanes had 1 pieces of work with a total of 131914 characters of text\n",
      "ipsavivere had 1 pieces of work with a total of 532 characters of text\n",
      "isidore had 1 pieces of work with a total of 43473 characters of text\n",
      "italicus had 1 pieces of work with a total of 51727 characters of text\n",
      "jacopoallegretti had 1 pieces of work with a total of 4595 characters of text\n",
      "janus had 1 pieces of work with a total of 9758 characters of text\n",
      "jerome had 80 pieces of work with a total of 6201228 characters of text\n",
      "jfkhonor had 1 pieces of work with a total of 1925 characters of text\n",
      "johannes had 1 pieces of work with a total of 81855 characters of text\n",
      "junillus had 1 pieces of work with a total of 71795 characters of text\n",
      "justin had 1 pieces of work with a total of 9316 characters of text\n",
      "justinian had 1 pieces of work with a total of 134315 characters of text\n",
      "juvenal had 1 pieces of work with a total of 170859 characters of text\n",
      "juvencus had 4 pieces of work with a total of 144617 characters of text\n",
      "kalila had 1 pieces of work with a total of 197267 characters of text\n",
      "kempis had 1 pieces of work with a total of 57776 characters of text\n",
      "kepler had 1 pieces of work with a total of 44519 characters of text\n",
      "lactantius had 1 pieces of work with a total of 122596 characters of text\n",
      "landor had 1 pieces of work with a total of 21815 characters of text\n",
      "legenda had 1 pieces of work with a total of 25365 characters of text\n",
      "leo had 1 pieces of work with a total of 41074 characters of text\n",
      "leothegreat had 1 pieces of work with a total of 8765 characters of text\n",
      "letabundus had 1 pieces of work with a total of 969 characters of text\n",
      "levis had 1 pieces of work with a total of 614 characters of text\n",
      "lhomond had 1 pieces of work with a total of 35760 characters of text\n",
      "liberpontificalis had 1 pieces of work with a total of 107856 characters of text\n",
      "livy had 4 pieces of work with a total of 3582763 characters of text\n",
      "lotichius had 1 pieces of work with a total of 921 characters of text\n",
      "lucan had 10 pieces of work with a total of 358610 characters of text\n",
      "lucernarium had 1 pieces of work with a total of 533 characters of text\n",
      "lucretius had 6 pieces of work with a total of 329870 characters of text\n",
      "luther had 1 pieces of work with a total of 5046 characters of text\n",
      "macarius had 1 pieces of work with a total of 32831 characters of text\n",
      "macrobius had 8 pieces of work with a total of 602168 characters of text\n",
      "magnacarta had 1 pieces of work with a total of 25334 characters of text\n",
      "maidstone had 1 pieces of work with a total of 12204 characters of text\n",
      "malaterra had 1 pieces of work with a total of 60216 characters of text\n",
      "manilius had 5 pieces of work with a total of 195808 characters of text\n",
      "mapps had 1 pieces of work with a total of 10434 characters of text\n",
      "marbodus had 1 pieces of work with a total of 11471 characters of text\n",
      "marcantonioaldegati had 1 pieces of work with a total of 48445 characters of text\n",
      "marcellinus had 1 pieces of work with a total of 79538 characters of text\n",
      "marcusmincuiusfelix had 1 pieces of work with a total of 82026 characters of text\n",
      "martial had 14 pieces of work with a total of 275032 characters of text\n",
      "martinbraga had 1 pieces of work with a total of 5255 characters of text\n",
      "marullo had 1 pieces of work with a total of 2388 characters of text\n",
      "marx had 1 pieces of work with a total of 6181 characters of text\n",
      "maximianus had 1 pieces of work with a total of 29420 characters of text\n",
      "may had 1 pieces of work with a total of 18038 characters of text\n",
      "melanchthon had 1 pieces of work with a total of 71805 characters of text\n",
      "milton had 1 pieces of work with a total of 10794 characters of text\n",
      "minucius had 1 pieces of work with a total of 82425 characters of text\n",
      "mirabilia had 1 pieces of work with a total of 32012 characters of text\n",
      "mirandola had 1 pieces of work with a total of 54274 characters of text\n",
      "montanus had 1 pieces of work with a total of 5494 characters of text\n",
      "more had 1 pieces of work with a total of 192797 characters of text\n",
      "musavenit had 1 pieces of work with a total of 627 characters of text\n",
      "naevius had 1 pieces of work with a total of 5843 characters of text\n",
      "navagero had 1 pieces of work with a total of 45281 characters of text\n",
      "nemesianus had 1 pieces of work with a total of 4018 characters of text\n",
      "nepos had 1 pieces of work with a total of 202032 characters of text\n",
      "newton had 1 pieces of work with a total of 10281 characters of text\n",
      "nithardus had 1 pieces of work with a total of 27648 characters of text\n",
      "nobilis had 1 pieces of work with a total of 604 characters of text\n",
      "notitia had 1 pieces of work with a total of 37953 characters of text\n",
      "novatian had 1 pieces of work with a total of 135244 characters of text\n",
      "obsequens had 1 pieces of work with a total of 39105 characters of text\n",
      "omnegenus had 1 pieces of work with a total of 1155 characters of text\n",
      "oratio had 1 pieces of work with a total of 6515 characters of text\n",
      "oresmius had 1 pieces of work with a total of 68052 characters of text\n",
      "origo had 1 pieces of work with a total of 6817 characters of text\n",
      "orosius had 1 pieces of work with a total of 66309 characters of text\n",
      "ottofreising had 1 pieces of work with a total of 114755 characters of text\n",
      "ovid had 41 pieces of work with a total of 1473588 characters of text\n",
      "owen had 1 pieces of work with a total of 3059 characters of text\n",
      "paris had 1 pieces of work with a total of 4805 characters of text\n",
      "pascoli had 1 pieces of work with a total of 6222 characters of text\n",
      "passerat had 1 pieces of work with a total of 3454 characters of text\n",
      "patricius had 1 pieces of work with a total of 21936 characters of text\n",
      "pauldeacon had 1 pieces of work with a total of 21421 characters of text\n",
      "paulinus had 1 pieces of work with a total of 173954 characters of text\n",
      "paulusdiaconus had 1 pieces of work with a total of 69912 characters of text\n",
      "perp had 1 pieces of work with a total of 24115 characters of text\n",
      "persius had 1 pieces of work with a total of 29733 characters of text\n",
      "pervig had 1 pieces of work with a total of 4300 characters of text\n",
      "petrarch had 1 pieces of work with a total of 5987 characters of text\n",
      "petrarchmedicus had 1 pieces of work with a total of 151780 characters of text\n",
      "petronius had 1 pieces of work with a total of 214546 characters of text\n",
      "petroniusfrag had 1 pieces of work with a total of 7962 characters of text\n",
      "phaedr had 1 pieces of work with a total of 7033 characters of text\n",
      "phaedrapp had 1 pieces of work with a total of 18127 characters of text\n",
      "piccolomini had 1 pieces of work with a total of 6556 characters of text\n",
      "planctus had 1 pieces of work with a total of 3076 characters of text\n",
      "plautus had 20 pieces of work with a total of 1062674 characters of text\n",
      "pliny had 1 pieces of work with a total of 57967 characters of text\n",
      "plinytheelder had 7 pieces of work with a total of 2810822 characters of text\n",
      "plinytheyounger had 10 pieces of work with a total of 467614 characters of text\n",
      "poggio had 1 pieces of work with a total of 100501 characters of text\n",
      "polignac had 3 pieces of work with a total of 898418 characters of text\n",
      "pomponius had 1 pieces of work with a total of 41047 characters of text\n",
      "pontano had 1 pieces of work with a total of 5989 characters of text\n",
      "poree had 1 pieces of work with a total of 57100 characters of text\n",
      "porphyrius had 1 pieces of work with a total of 34744 characters of text\n",
      "potatores had 1 pieces of work with a total of 1022 characters of text\n",
      "prataiam had 1 pieces of work with a total of 738 characters of text\n",
      "prec had 1 pieces of work with a total of 1374 characters of text\n",
      "precatio had 1 pieces of work with a total of 899 characters of text\n",
      "priapea had 1 pieces of work with a total of 23249 characters of text\n",
      "priscian had 4 pieces of work with a total of 125385 characters of text\n",
      "professio had 1 pieces of work with a total of 8725 characters of text\n",
      "prop had 1 pieces of work with a total of 39553 characters of text\n",
      "propertius had 1 pieces of work with a total of 164271 characters of text\n",
      "prosperus had 1 pieces of work with a total of 99991 characters of text\n",
      "protospatarius had 1 pieces of work with a total of 30329 characters of text\n",
      "prudentius had 7 pieces of work with a total of 238798 characters of text\n",
      "pseudocicero had 1 pieces of work with a total of 12256 characters of text\n",
      "pseudoquintilian had 1 pieces of work with a total of 475491 characters of text\n",
      "psplato had 1 pieces of work with a total of 8802 characters of text\n",
      "pulchracomis had 1 pieces of work with a total of 217 characters of text\n",
      "qcicero had 1 pieces of work with a total of 28874 characters of text\n",
      "quintilian had 12 pieces of work with a total of 1183641 characters of text\n",
      "quum had 1 pieces of work with a total of 2281 characters of text\n",
      "raoul had 1 pieces of work with a total of 268357 characters of text\n",
      "regula had 1 pieces of work with a total of 40185 characters of text\n",
      "reposianus had 1 pieces of work with a total of 8568 characters of text\n",
      "resgestae had 1 pieces of work with a total of 19561 characters of text\n",
      "rhetores had 1 pieces of work with a total of 678 characters of text\n",
      "richerus had 1 pieces of work with a total of 101221 characters of text\n",
      "rimbaud had 1 pieces of work with a total of 2988 characters of text\n",
      "ruaeus had 1 pieces of work with a total of 17523 characters of text\n",
      "rumor had 1 pieces of work with a total of 943 characters of text\n",
      "rutilius had 1 pieces of work with a total of 29644 characters of text\n",
      "rutiliuslupus had 1 pieces of work with a total of 31477 characters of text\n",
      "sabinus had 1 pieces of work with a total of 4623 characters of text\n",
      "sall had 1 pieces of work with a total of 150818 characters of text\n",
      "sallust had 3 pieces of work with a total of 254194 characters of text\n",
      "sannazaro had 1 pieces of work with a total of 65699 characters of text\n",
      "scaliger had 1 pieces of work with a total of 294 characters of text\n",
      "scbaccanalibus had 1 pieces of work with a total of 4922 characters of text\n",
      "scottus had 1 pieces of work with a total of 1589 characters of text\n",
      "scriptoreshistoriaeaugustae had 4 pieces of work with a total of 527723 characters of text\n",
      "sedulius had 1 pieces of work with a total of 14042 characters of text\n",
      "sen had 1 pieces of work with a total of 53425 characters of text\n",
      "seneca had 42 pieces of work with a total of 2155204 characters of text\n",
      "senecatheelder had 8 pieces of work with a total of 666264 characters of text\n",
      "septsap had 1 pieces of work with a total of 49331 characters of text\n",
      "serviushonoratus had 4 pieces of work with a total of 355299 characters of text\n",
      "sha had 1 pieces of work with a total of 19068 characters of text\n",
      "sicmeafata had 1 pieces of work with a total of 798 characters of text\n",
      "sidonius had 1 pieces of work with a total of 42650 characters of text\n",
      "sigebert had 1 pieces of work with a total of 10679 characters of text\n",
      "silius had 1 pieces of work with a total of 30850 characters of text\n",
      "siliusitalicus had 17 pieces of work with a total of 538363 characters of text\n",
      "simedignetur had 1 pieces of work with a total of 308 characters of text\n",
      "smarius had 1 pieces of work with a total of 6792 characters of text\n",
      "solet had 1 pieces of work with a total of 11763 characters of text\n",
      "solinus had 1 pieces of work with a total of 241481 characters of text\n",
      "spinoza had 1 pieces of work with a total of 117778 characters of text\n",
      "statius had 18 pieces of work with a total of 656190 characters of text\n",
      "suetonius had 12 pieces of work with a total of 518934 characters of text\n",
      "sulpicia had 1 pieces of work with a total of 1697 characters of text\n",
      "sulpiciusseveruschron had 1 pieces of work with a total of 92885 characters of text\n",
      "sulpiciusseverusmartin had 1 pieces of work with a total of 48368 characters of text\n",
      "suscipeflos had 1 pieces of work with a total of 417 characters of text\n",
      "syrus had 1 pieces of work with a total of 56263 characters of text\n",
      "tacitus had 20 pieces of work with a total of 1204956 characters of text\n",
      "tempusest had 1 pieces of work with a total of 1210 characters of text\n",
      "ter had 1 pieces of work with a total of 61820 characters of text\n",
      "terence had 6 pieces of work with a total of 310741 characters of text\n",
      "terraiam had 1 pieces of work with a total of 1107 characters of text\n",
      "tertullian had 2 pieces of work with a total of 186130 characters of text\n",
      "testamentum had 1 pieces of work with a total of 2192 characters of text\n",
      "tevigilans had 1 pieces of work with a total of 351 characters of text\n",
      "theganus had 1 pieces of work with a total of 45690 characters of text\n",
      "theodolus had 1 pieces of work with a total of 16262 characters of text\n",
      "theodosius had 1 pieces of work with a total of 143782 characters of text\n",
      "theophanes had 1 pieces of work with a total of 1930 characters of text\n",
      "thesauro had 1 pieces of work with a total of 12371 characters of text\n",
      "thomasedessa had 1 pieces of work with a total of 73511 characters of text\n",
      "tibullus had 1 pieces of work with a total of 80686 characters of text\n",
      "tunger had 1 pieces of work with a total of 89239 characters of text\n",
      "valeriusflaccus had 8 pieces of work with a total of 278759 characters of text\n",
      "valeriusmaximus had 9 pieces of work with a total of 586001 characters of text\n",
      "valesianus had 1 pieces of work with a total of 120 characters of text\n",
      "valmax had 1 pieces of work with a total of 68958 characters of text\n",
      "varro had 1 pieces of work with a total of 33190 characters of text\n",
      "vegetius had 1 pieces of work with a total of 72149 characters of text\n",
      "vegius had 1 pieces of work with a total of 29868 characters of text\n",
      "vell had 1 pieces of work with a total of 167143 characters of text\n",
      "venantius had 1 pieces of work with a total of 5002 characters of text\n",
      "vergil had 17 pieces of work with a total of 579350 characters of text\n",
      "vicentius had 1 pieces of work with a total of 121964 characters of text\n",
      "vico had 1 pieces of work with a total of 21838 characters of text\n",
      "victor had 1 pieces of work with a total of 69412 characters of text\n",
      "vida had 1 pieces of work with a total of 30105 characters of text\n",
      "vitacaroli had 1 pieces of work with a total of 104331 characters of text\n",
      "vitruvius had 10 pieces of work with a total of 421054 characters of text\n",
      "volovirum had 1 pieces of work with a total of 1071 characters of text\n",
      "voragine had 1 pieces of work with a total of 3830 characters of text\n",
      "waardenburg had 1 pieces of work with a total of 3553 characters of text\n",
      "waltarius had 1 pieces of work with a total of 18263 characters of text\n",
      "walter had 1 pieces of work with a total of 2305 characters of text\n",
      "walton had 1 pieces of work with a total of 26036 characters of text\n",
      "williamapulia had 1 pieces of work with a total of 123908 characters of text\n",
      "williamtyre had 1 pieces of work with a total of 87915 characters of text\n",
      "withof had 1 pieces of work with a total of 7151 characters of text\n",
      "wmconchesdogma had 1 pieces of work with a total of 91687 characters of text\n",
      "wmconchesphil had 1 pieces of work with a total of 39080 characters of text\n",
      "xanten had 1 pieces of work with a total of 49919 characters of text\n",
      "xylander had 1 pieces of work with a total of 106561 characters of text\n",
      "zonaras had 1 pieces of work with a total of 76548 characters of text\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LanguageModel\n",
      "File \u001b[0;32m/notebooks/transformer.py:108\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03mstoi = {ch:i for i, ch in enumerate(chars)}\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mitos = { i:ch for i,ch in enumerate(chars)}\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03mencode = lambda s: [stoi[c] for c in s] \u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03mdecode = lambda l: ''.join([itos[i] for i in l])\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03mdef encode(totalText):\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    sents = st.tokenize(totalText)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mdecode = lambda l: [w2v.get_sims(v)[0][0] for v in l]\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Let's create a train/val split\u001b[39;00m\n\u001b[1;32m    111\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m.8\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(data)) \n",
      "File \u001b[0;32m/notebooks/transformer.py:73\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(totalText)\u001b[0m\n\u001b[1;32m     71\u001b[0m paddedPuncs \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([.,!?:;()])\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1 \u001b[39m\u001b[38;5;124m'\u001b[39m, totalText)\n\u001b[1;32m     72\u001b[0m paddedPuncs \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m2,}\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, paddedPuncs)\n\u001b[0;32m---> 73\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mwt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaddedPuncs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/cltk/tokenizers/lat/lat.py:109\u001b[0m, in \u001b[0;36mLatinWordTokenizer.tokenize\u001b[0;34m(self, text, replacements, enclitics_exceptions, enclitics)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m replacement \u001b[38;5;129;01min\u001b[39;00m replacements:\n\u001b[1;32m    105\u001b[0m     text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    106\u001b[0m         replacement[\u001b[38;5;241m0\u001b[39m], matchcase(replacement[\u001b[38;5;241m1\u001b[39m]), text, flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mIGNORECASE\n\u001b[1;32m    107\u001b[0m     )\n\u001b[0;32m--> 109\u001b[0m sents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msent_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m tokens \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# type: List[str]\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sents:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/cltk/sentence/sentence.py:55\u001b[0m, in \u001b[0;36mSentenceTokenizer.tokenize\u001b[0;34m(self, text, model)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang_vars:\n\u001b[1;32m     54\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39m_lang_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang_vars\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py:1276\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, realign_boundaries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;124;03m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py:1332\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, realign_boundaries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py:1332\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, realign_boundaries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py:1322\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m realign_boundaries:\n\u001b[1;32m   1321\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[0;32m-> 1322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m slices:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (sentence\u001b[38;5;241m.\u001b[39mstart, sentence\u001b[38;5;241m.\u001b[39mstop)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py:1421\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;124;03mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;124;03mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;124;03m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m realign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence1, sentence2 \u001b[38;5;129;01min\u001b[39;00m _pair_iter(slices):\n\u001b[1;32m   1422\u001b[0m     sentence1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(sentence1\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m realign, sentence1\u001b[38;5;241m.\u001b[39mstop)\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sentence2:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py:318\u001b[0m, in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    316\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py:1395\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slices_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m   1394\u001b[0m     last_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1395\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m match, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_potential_end_contexts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1396\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_contains_sentbreak(context):\n\u001b[1;32m   1397\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(last_break, match\u001b[38;5;241m.\u001b[39mend())\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/tokenize/punkt.py:1380\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._match_potential_end_contexts\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# Find the word before the current match\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxsplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1381\u001b[0m before_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(split[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(split) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1382\u001b[0m before_words[match] \u001b[38;5;241m=\u001b[39m split[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, re\n",
    "from Data import dataExp\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "    from cltk.tokenizers.lat.lat import LatinWordTokenizer as WordTokenizer\n",
    "    from cltk.tokenizers.lat.lat import LatinPunktSentenceTokenizer as SentenceTokenizer\n",
    "from cltk.embeddings.embeddings import Word2VecEmbeddings as W2VE\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformer import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b34985af-3f00-4294-a31c-bea2d0f28799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-15T16:50:54.027113Z",
     "iopub.status.busy": "2023-03-15T16:50:54.026816Z",
     "iopub.status.idle": "2023-03-15T16:50:56.148131Z",
     "shell.execute_reply": "2023-03-15T16:50:56.147520Z",
     "shell.execute_reply.started": "2023-03-15T16:50:54.027090Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load('LatinTransformer/model_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484cd67f-a946-4fc1-9140-e542b16b5782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-15T16:51:27.922993Z",
     "iopub.status.busy": "2023-03-15T16:51:27.922187Z",
     "iopub.status.idle": "2023-03-15T16:51:27.925659Z",
     "shell.execute_reply": "2023-03-15T16:51:27.925198Z",
     "shell.execute_reply.started": "2023-03-15T16:51:27.922965Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformer import encode, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef69a3a-669a-4305-821d-f3d4b3cc9746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-15T16:52:28.269639Z",
     "iopub.status.busy": "2023-03-15T16:52:28.269025Z",
     "iopub.status.idle": "2023-03-15T16:52:28.273948Z",
     "shell.execute_reply": "2023-03-15T16:52:28.273389Z",
     "shell.execute_reply.started": "2023-03-15T16:52:28.269607Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "context = torch.tensor(encode(\"Gallia est omnis divisa in partes tres\".lower()), dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16cfe054-e1b9-4da3-a9e5-e29c70f62374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-15T16:53:18.076583Z",
     "iopub.status.busy": "2023-03-15T16:53:18.075700Z",
     "iopub.status.idle": "2023-03-15T16:53:18.090964Z",
     "shell.execute_reply": "2023-03-15T16:53:18.090148Z",
     "shell.execute_reply.started": "2023-03-15T16:53:18.076546Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decode(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m(context, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "decode(model.generate(context, max_new_tokens=10000)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4328d530-bc09-4a49-9efd-8653d4a40ce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T14:57:37.962486Z",
     "iopub.status.busy": "2023-03-18T14:57:37.961334Z",
     "iopub.status.idle": "2023-03-18T14:57:38.115975Z",
     "shell.execute_reply": "2023-03-18T14:57:38.115127Z",
     "shell.execute_reply.started": "2023-03-18T14:57:37.962440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the existing corpus\n",
      "abbofloracensis had 1 pieces of work with a total of 34398 characters of text\n",
      "abelard had 1 pieces of work with a total of 15483 characters of text\n",
      "acticussincerius had 1 pieces of work with a total of 5947 characters of text\n",
      "addison had 1 pieces of work with a total of 3074 characters of text\n",
      "adso had 1 pieces of work with a total of 13551 characters of text\n",
      "aelredus had 1 pieces of work with a total of 118173 characters of text\n",
      "agnes had 1 pieces of work with a total of 74784 characters of text\n",
      "alanus had 1 pieces of work with a total of 136527 characters of text\n",
      "albericodamarcellise had 1 pieces of work with a total of 172 characters of text\n",
      "albertanus had 1 pieces of work with a total of 108213 characters of text\n",
      "albertofaix had 1 pieces of work with a total of 51703 characters of text\n",
      "alcuin had 1 pieces of work with a total of 1641 characters of text\n",
      "aleandrogerolamo had 1 pieces of work with a total of 10197 characters of text\n",
      "alfonsi had 1 pieces of work with a total of 105630 characters of text\n",
      "ambrose had 1 pieces of work with a total of 15147 characters of text\n",
      "ammianus had 18 pieces of work with a total of 975460 characters of text\n",
      "ampelius had 1 pieces of work with a total of 52872 characters of text\n",
      "andecavis had 1 pieces of work with a total of 920 characters of text\n",
      "andreasbergoma had 1 pieces of work with a total of 28522 characters of text\n",
      "andronicus had 1 pieces of work with a total of 2238 characters of text\n",
      "angeloambrogini had 1 pieces of work with a total of 6096 characters of text\n",
      "angelopoliziano had 1 pieces of work with a total of 2637 characters of text\n",
      "angilbert had 1 pieces of work with a total of 2094 characters of text\n",
      "annalesregnifrancorum had 1 pieces of work with a total of 155834 characters of text\n",
      "annalesvedastini had 1 pieces of work with a total of 54567 characters of text\n",
      "anon had 1 pieces of work with a total of 793 characters of text\n",
      "anonymous had 1 pieces of work with a total of 6463 characters of text\n",
      "anselmepistula had 1 pieces of work with a total of 5009 characters of text\n",
      "anselmproslogion had 1 pieces of work with a total of 39144 characters of text\n",
      "apicius had 1 pieces of work with a total of 8603 characters of text\n",
      "appverg had 1 pieces of work with a total of 8895 characters of text\n",
      "appvergcomp had 1 pieces of work with a total of 110025 characters of text\n",
      "appvergculex had 1 pieces of work with a total of 18887 characters of text\n",
      "apuleius had 13 pieces of work with a total of 604335 characters of text\n",
      "aquinas had 1 pieces of work with a total of 33728 characters of text\n",
      "arbroath had 1 pieces of work with a total of 7497 characters of text\n",
      "archpoet had 1 pieces of work with a total of 29641 characters of text\n",
      "aristotle had 1 pieces of work with a total of 11537 characters of text\n",
      "arnobius had 1 pieces of work with a total of 66612 characters of text\n",
      "arnulf had 1 pieces of work with a total of 1387 characters of text\n",
      "asconius had 1 pieces of work with a total of 112203 characters of text\n",
      "asserius had 1 pieces of work with a total of 89247 characters of text\n",
      "augustine had 7 pieces of work with a total of 402151 characters of text\n",
      "aureliusvictor had 2 pieces of work with a total of 149735 characters of text\n",
      "aus had 1 pieces of work with a total of 2241 characters of text\n",
      "ausonius had 24 pieces of work with a total of 292442 characters of text\n",
      "ave had 1 pieces of work with a total of 6949 characters of text\n",
      "avianus had 1 pieces of work with a total of 30263 characters of text\n",
      "avienus had 1 pieces of work with a total of 27798 characters of text\n",
      "axio had 1 pieces of work with a total of 16543 characters of text\n",
      "bacon had 1 pieces of work with a total of 45816 characters of text\n",
      "balbus had 1 pieces of work with a total of 16073 characters of text\n",
      "balde had 1 pieces of work with a total of 765 characters of text\n",
      "baldo had 1 pieces of work with a total of 59162 characters of text\n",
      "bebel had 1 pieces of work with a total of 131504 characters of text\n",
      "bede had 5 pieces of work with a total of 575775 characters of text\n",
      "benedict had 1 pieces of work with a total of 92323 characters of text\n",
      "berengar had 1 pieces of work with a total of 37827 characters of text\n",
      "bernardcluny had 1 pieces of work with a total of 62164 characters of text\n",
      "bible had 1 pieces of work with a total of 91761 characters of text\n",
      "biggs had 1 pieces of work with a total of 44386 characters of text\n",
      "bill had 1 pieces of work with a total of 3236 characters of text\n",
      "blesensis had 1 pieces of work with a total of 51232 characters of text\n",
      "boethius had 10 pieces of work with a total of 263001 characters of text\n",
      "boethiusdacia had 1 pieces of work with a total of 50991 characters of text\n",
      "bonaventura had 1 pieces of work with a total of 72084 characters of text\n",
      "boskovic had 1 pieces of work with a total of 22752 characters of text\n",
      "brevechronicon had 1 pieces of work with a total of 8191 characters of text\n",
      "buchanan had 1 pieces of work with a total of 36240 characters of text\n",
      "bultelius had 1 pieces of work with a total of 2472 characters of text\n",
      "caeciliusbalbus had 1 pieces of work with a total of 45340 characters of text\n",
      "caesar had 11 pieces of work with a total of 616439 characters of text\n",
      "caesaraugustus had 1 pieces of work with a total of 18129 characters of text\n",
      "calpurniusflaccus had 1 pieces of work with a total of 48342 characters of text\n",
      "calpurniussiculus had 1 pieces of work with a total of 34152 characters of text\n",
      "campion had 1 pieces of work with a total of 13502 characters of text\n",
      "capellanus had 1 pieces of work with a total of 233924 characters of text\n",
      "carm had 1 pieces of work with a total of 1530 characters of text\n",
      "carmenarvale had 1 pieces of work with a total of 560 characters of text\n",
      "carmeninvictoriam had 1 pieces of work with a total of 13588 characters of text\n",
      "carmensaliare had 1 pieces of work with a total of 306 characters of text\n",
      "cassiodorus had 1 pieces of work with a total of 80306 characters of text\n",
      "catalogueliberien had 1 pieces of work with a total of 7213 characters of text\n",
      "cato had 1 pieces of work with a total of 14361 characters of text\n",
      "catullus had 1 pieces of work with a total of 85900 characters of text\n",
      "celsus had 8 pieces of work with a total of 696619 characters of text\n",
      "celtis had 1 pieces of work with a total of 1855 characters of text\n",
      "censorinus had 1 pieces of work with a total of 71644 characters of text\n",
      "cicero had 122 pieces of work with a total of 7438016 characters of text\n",
      "cinna had 1 pieces of work with a total of 861 characters of text\n",
      "claud had 1 pieces of work with a total of 4961 characters of text\n",
      "claudian had 19 pieces of work with a total of 441142 characters of text\n",
      "clitophon had 1 pieces of work with a total of 9925 characters of text\n",
      "colman had 1 pieces of work with a total of 1737 characters of text\n",
      "columba had 1 pieces of work with a total of 69044 characters of text\n",
      "columbus had 1 pieces of work with a total of 15591 characters of text\n",
      "columella had 9 pieces of work with a total of 562550 characters of text\n",
      "comes had 1 pieces of work with a total of 441 characters of text\n",
      "commodianus had 1 pieces of work with a total of 939 characters of text\n",
      "corippus had 8 pieces of work with a total of 217825 characters of text\n",
      "corneliopaoloamalteo had 1 pieces of work with a total of 503 characters of text\n",
      "corvinus had 1 pieces of work with a total of 4815 characters of text\n",
      "cotta had 1 pieces of work with a total of 12574 characters of text\n",
      "creeds had 1 pieces of work with a total of 6010 characters of text\n",
      "curtius had 1 pieces of work with a total of 51880 characters of text\n",
      "curtiusrufus had 8 pieces of work with a total of 536805 characters of text\n",
      "dante had 1 pieces of work with a total of 3188 characters of text\n",
      "dantealighieri had 1 pieces of work with a total of 120 characters of text\n",
      "dares had 1 pieces of work with a total of 56639 characters of text\n",
      "debury had 1 pieces of work with a total of 115993 characters of text\n",
      "declaratio had 1 pieces of work with a total of 10290 characters of text\n",
      "decretum had 1 pieces of work with a total of 15220 characters of text\n",
      "descartes had 1 pieces of work with a total of 5221 characters of text\n",
      "dicquid had 1 pieces of work with a total of 328 characters of text\n",
      "diesirae had 1 pieces of work with a total of 1430 characters of text\n",
      "diravi had 1 pieces of work with a total of 795 characters of text\n",
      "don had 1 pieces of work with a total of 29181 characters of text\n",
      "donation had 1 pieces of work with a total of 20027 characters of text\n",
      "dracontius had 16 pieces of work with a total of 266831 characters of text\n",
      "dumdiane had 1 pieces of work with a total of 1532 characters of text\n",
      "dumdomus had 1 pieces of work with a total of 349 characters of text\n",
      "ebulo had 1 pieces of work with a total of 73683 characters of text\n",
      "egeria had 1 pieces of work with a total of 53062 characters of text\n",
      "ein had 1 pieces of work with a total of 54962 characters of text\n",
      "enn had 1 pieces of work with a total of 8355 characters of text\n",
      "ennius had 1 pieces of work with a total of 25266 characters of text\n",
      "ennodius had 1 pieces of work with a total of 75591 characters of text\n",
      "ep had 1 pieces of work with a total of 18656 characters of text\n",
      "epistaustras had 1 pieces of work with a total of 34585 characters of text\n",
      "epitaphs had 1 pieces of work with a total of 10341 characters of text\n",
      "epitomecononiana had 1 pieces of work with a total of 39045 characters of text\n",
      "epitomefeliciana had 1 pieces of work with a total of 44673 characters of text\n",
      "erasmus had 1 pieces of work with a total of 177122 characters of text\n",
      "erchempert had 1 pieces of work with a total of 89824 characters of text\n",
      "estas had 1 pieces of work with a total of 597 characters of text\n",
      "eucherius had 1 pieces of work with a total of 28159 characters of text\n",
      "eugenius had 1 pieces of work with a total of 584 characters of text\n",
      "eugippius had 1 pieces of work with a total of 87808 characters of text\n",
      "eutropius had 1 pieces of work with a total of 133407 characters of text\n",
      "exivi had 1 pieces of work with a total of 30157 characters of text\n",
      "fabe had 1 pieces of work with a total of 31196 characters of text\n",
      "falcandus had 1 pieces of work with a total of 262882 characters of text\n",
      "falcone had 1 pieces of work with a total of 273400 characters of text\n",
      "faustoandrelino had 1 pieces of work with a total of 4769 characters of text\n",
      "ferraria had 1 pieces of work with a total of 18083 characters of text\n",
      "ficino had 1 pieces of work with a total of 20924 characters of text\n",
      "fletcher had 1 pieces of work with a total of 41616 characters of text\n",
      "florus had 1 pieces of work with a total of 188724 characters of text\n",
      "foedusaeternum had 1 pieces of work with a total of 3611 characters of text\n",
      "forsett had 1 pieces of work with a total of 33474 characters of text\n",
      "fortunat had 1 pieces of work with a total of 703 characters of text\n",
      "fragmentumlaurentianum had 1 pieces of work with a total of 6067 characters of text\n",
      "fredegarius had 1 pieces of work with a total of 168136 characters of text\n",
      "frodebertus had 1 pieces of work with a total of 6475 characters of text\n",
      "frontinus had 1 pieces of work with a total of 6813 characters of text\n",
      "fronto had 1 pieces of work with a total of 339779 characters of text\n",
      "fulbert had 1 pieces of work with a total of 760 characters of text\n",
      "fulgentius had 1 pieces of work with a total of 28596 characters of text\n",
      "gaius had 1 pieces of work with a total of 78184 characters of text\n",
      "galileo had 1 pieces of work with a total of 71985 characters of text\n",
      "garcilaso had 1 pieces of work with a total of 6652 characters of text\n",
      "garland had 1 pieces of work with a total of 21499 characters of text\n",
      "gaud had 1 pieces of work with a total of 811 characters of text\n",
      "gauss had 1 pieces of work with a total of 66500 characters of text\n",
      "gellius had 21 pieces of work with a total of 812717 characters of text\n",
      "germanicus had 1 pieces of work with a total of 33114 characters of text\n",
      "gestafrancorum had 1 pieces of work with a total of 8247 characters of text\n",
      "gestarom had 1 pieces of work with a total of 103434 characters of text\n",
      "gioacchino had 1 pieces of work with a total of 136901 characters of text\n",
      "girolamoaccelini had 1 pieces of work with a total of 3935 characters of text\n",
      "girolamoamaseo had 1 pieces of work with a total of 16479 characters of text\n",
      "glass had 1 pieces of work with a total of 190152 characters of text\n",
      "godfrey had 1 pieces of work with a total of 48392 characters of text\n",
      "grattius had 1 pieces of work with a total of 24829 characters of text\n",
      "gravissimas had 1 pieces of work with a total of 13221 characters of text\n",
      "greg had 1 pieces of work with a total of 5508 characters of text\n",
      "gregdecretals had 1 pieces of work with a total of 663928 characters of text\n",
      "gregory had 1 pieces of work with a total of 119429 characters of text\n",
      "gregorytours had 1 pieces of work with a total of 93341 characters of text\n",
      "gwinne had 1 pieces of work with a total of 23392 characters of text\n",
      "halley had 1 pieces of work with a total of 2243 characters of text\n",
      "hebet had 1 pieces of work with a total of 660 characters of text\n",
      "henry had 1 pieces of work with a total of 6543 characters of text\n",
      "henrysettimello had 1 pieces of work with a total of 42703 characters of text\n",
      "hipp had 1 pieces of work with a total of 13938 characters of text\n",
      "histapoll had 1 pieces of work with a total of 79949 characters of text\n",
      "histbrit had 1 pieces of work with a total of 64287 characters of text\n",
      "holberg had 1 pieces of work with a total of 208989 characters of text\n",
      "horace had 10 pieces of work with a total of 297826 characters of text\n",
      "hrabanus had 1 pieces of work with a total of 1155 characters of text\n",
      "hugo had 1 pieces of work with a total of 53280 characters of text\n",
      "hydatiuschronicon had 1 pieces of work with a total of 40888 characters of text\n",
      "hydatiusfasti had 1 pieces of work with a total of 45910 characters of text\n",
      "hyginus had 1 pieces of work with a total of 75886 characters of text\n",
      "hymni had 1 pieces of work with a total of 10922 characters of text\n",
      "iabervocius had 1 pieces of work with a total of 4204 characters of text\n",
      "iamdulcis had 1 pieces of work with a total of 1239 characters of text\n",
      "ilias had 1 pieces of work with a total of 47469 characters of text\n",
      "index had 1 pieces of work with a total of 1604 characters of text\n",
      "indices had 1 pieces of work with a total of 1860 characters of text\n",
      "innocent had 1 pieces of work with a total of 101995 characters of text\n",
      "inquisitio had 1 pieces of work with a total of 28586 characters of text\n",
      "inscriptions had 1 pieces of work with a total of 5249 characters of text\n",
      "iordanes had 1 pieces of work with a total of 131914 characters of text\n",
      "ipsavivere had 1 pieces of work with a total of 532 characters of text\n",
      "isidore had 1 pieces of work with a total of 43473 characters of text\n",
      "italicus had 1 pieces of work with a total of 51727 characters of text\n",
      "jacopoallegretti had 1 pieces of work with a total of 4595 characters of text\n",
      "janus had 1 pieces of work with a total of 9758 characters of text\n",
      "jerome had 80 pieces of work with a total of 6201228 characters of text\n",
      "jfkhonor had 1 pieces of work with a total of 1925 characters of text\n",
      "johannes had 1 pieces of work with a total of 81855 characters of text\n",
      "junillus had 1 pieces of work with a total of 71795 characters of text\n",
      "justin had 1 pieces of work with a total of 9316 characters of text\n",
      "justinian had 1 pieces of work with a total of 134315 characters of text\n",
      "juvenal had 1 pieces of work with a total of 170859 characters of text\n",
      "juvencus had 4 pieces of work with a total of 144617 characters of text\n",
      "kalila had 1 pieces of work with a total of 197267 characters of text\n",
      "kempis had 1 pieces of work with a total of 57776 characters of text\n",
      "kepler had 1 pieces of work with a total of 44519 characters of text\n",
      "lactantius had 1 pieces of work with a total of 122596 characters of text\n",
      "landor had 1 pieces of work with a total of 21815 characters of text\n",
      "legenda had 1 pieces of work with a total of 25365 characters of text\n",
      "leo had 1 pieces of work with a total of 41074 characters of text\n",
      "leothegreat had 1 pieces of work with a total of 8765 characters of text\n",
      "letabundus had 1 pieces of work with a total of 969 characters of text\n",
      "levis had 1 pieces of work with a total of 614 characters of text\n",
      "lhomond had 1 pieces of work with a total of 35760 characters of text\n",
      "liberpontificalis had 1 pieces of work with a total of 107856 characters of text\n",
      "livy had 4 pieces of work with a total of 3582763 characters of text\n",
      "lotichius had 1 pieces of work with a total of 921 characters of text\n",
      "lucan had 10 pieces of work with a total of 358610 characters of text\n",
      "lucernarium had 1 pieces of work with a total of 533 characters of text\n",
      "lucretius had 6 pieces of work with a total of 329870 characters of text\n",
      "luther had 1 pieces of work with a total of 5046 characters of text\n",
      "macarius had 1 pieces of work with a total of 32831 characters of text\n",
      "macrobius had 8 pieces of work with a total of 602168 characters of text\n",
      "magnacarta had 1 pieces of work with a total of 25334 characters of text\n",
      "maidstone had 1 pieces of work with a total of 12204 characters of text\n",
      "malaterra had 1 pieces of work with a total of 60216 characters of text\n",
      "manilius had 5 pieces of work with a total of 195808 characters of text\n",
      "mapps had 1 pieces of work with a total of 10434 characters of text\n",
      "marbodus had 1 pieces of work with a total of 11471 characters of text\n",
      "marcantonioaldegati had 1 pieces of work with a total of 48445 characters of text\n",
      "marcellinus had 1 pieces of work with a total of 79538 characters of text\n",
      "marcusmincuiusfelix had 1 pieces of work with a total of 82026 characters of text\n",
      "martial had 14 pieces of work with a total of 275032 characters of text\n",
      "martinbraga had 1 pieces of work with a total of 5255 characters of text\n",
      "marullo had 1 pieces of work with a total of 2388 characters of text\n",
      "marx had 1 pieces of work with a total of 6181 characters of text\n",
      "maximianus had 1 pieces of work with a total of 29420 characters of text\n",
      "may had 1 pieces of work with a total of 18038 characters of text\n",
      "melanchthon had 1 pieces of work with a total of 71805 characters of text\n",
      "milton had 1 pieces of work with a total of 10794 characters of text\n",
      "minucius had 1 pieces of work with a total of 82425 characters of text\n",
      "mirabilia had 1 pieces of work with a total of 32012 characters of text\n",
      "mirandola had 1 pieces of work with a total of 54274 characters of text\n",
      "montanus had 1 pieces of work with a total of 5494 characters of text\n",
      "more had 1 pieces of work with a total of 192797 characters of text\n",
      "musavenit had 1 pieces of work with a total of 627 characters of text\n",
      "naevius had 1 pieces of work with a total of 5843 characters of text\n",
      "navagero had 1 pieces of work with a total of 45281 characters of text\n",
      "nemesianus had 1 pieces of work with a total of 4018 characters of text\n",
      "nepos had 1 pieces of work with a total of 202032 characters of text\n",
      "newton had 1 pieces of work with a total of 10281 characters of text\n",
      "nithardus had 1 pieces of work with a total of 27648 characters of text\n",
      "nobilis had 1 pieces of work with a total of 604 characters of text\n",
      "notitia had 1 pieces of work with a total of 37953 characters of text\n",
      "novatian had 1 pieces of work with a total of 135244 characters of text\n",
      "obsequens had 1 pieces of work with a total of 39105 characters of text\n",
      "omnegenus had 1 pieces of work with a total of 1155 characters of text\n",
      "oratio had 1 pieces of work with a total of 6515 characters of text\n",
      "oresmius had 1 pieces of work with a total of 68052 characters of text\n",
      "origo had 1 pieces of work with a total of 6817 characters of text\n",
      "orosius had 1 pieces of work with a total of 66309 characters of text\n",
      "ottofreising had 1 pieces of work with a total of 114755 characters of text\n",
      "ovid had 41 pieces of work with a total of 1473588 characters of text\n",
      "owen had 1 pieces of work with a total of 3059 characters of text\n",
      "paris had 1 pieces of work with a total of 4805 characters of text\n",
      "pascoli had 1 pieces of work with a total of 6222 characters of text\n",
      "passerat had 1 pieces of work with a total of 3454 characters of text\n",
      "patricius had 1 pieces of work with a total of 21936 characters of text\n",
      "pauldeacon had 1 pieces of work with a total of 21421 characters of text\n",
      "paulinus had 1 pieces of work with a total of 173954 characters of text\n",
      "paulusdiaconus had 1 pieces of work with a total of 69912 characters of text\n",
      "perp had 1 pieces of work with a total of 24115 characters of text\n",
      "persius had 1 pieces of work with a total of 29733 characters of text\n",
      "pervig had 1 pieces of work with a total of 4300 characters of text\n",
      "petrarch had 1 pieces of work with a total of 5987 characters of text\n",
      "petrarchmedicus had 1 pieces of work with a total of 151780 characters of text\n",
      "petronius had 1 pieces of work with a total of 214546 characters of text\n",
      "petroniusfrag had 1 pieces of work with a total of 7962 characters of text\n",
      "phaedr had 1 pieces of work with a total of 7033 characters of text\n",
      "phaedrapp had 1 pieces of work with a total of 18127 characters of text\n",
      "piccolomini had 1 pieces of work with a total of 6556 characters of text\n",
      "planctus had 1 pieces of work with a total of 3076 characters of text\n",
      "plautus had 20 pieces of work with a total of 1062674 characters of text\n",
      "pliny had 1 pieces of work with a total of 57967 characters of text\n",
      "plinytheelder had 7 pieces of work with a total of 2810822 characters of text\n",
      "plinytheyounger had 10 pieces of work with a total of 467614 characters of text\n",
      "poggio had 1 pieces of work with a total of 100501 characters of text\n",
      "polignac had 3 pieces of work with a total of 898418 characters of text\n",
      "pomponius had 1 pieces of work with a total of 41047 characters of text\n",
      "pontano had 1 pieces of work with a total of 5989 characters of text\n",
      "poree had 1 pieces of work with a total of 57100 characters of text\n",
      "porphyrius had 1 pieces of work with a total of 34744 characters of text\n",
      "potatores had 1 pieces of work with a total of 1022 characters of text\n",
      "prataiam had 1 pieces of work with a total of 738 characters of text\n",
      "prec had 1 pieces of work with a total of 1374 characters of text\n",
      "precatio had 1 pieces of work with a total of 899 characters of text\n",
      "priapea had 1 pieces of work with a total of 23249 characters of text\n",
      "priscian had 4 pieces of work with a total of 125385 characters of text\n",
      "professio had 1 pieces of work with a total of 8725 characters of text\n",
      "prop had 1 pieces of work with a total of 39553 characters of text\n",
      "propertius had 1 pieces of work with a total of 164271 characters of text\n",
      "prosperus had 1 pieces of work with a total of 99991 characters of text\n",
      "protospatarius had 1 pieces of work with a total of 30329 characters of text\n",
      "prudentius had 7 pieces of work with a total of 238798 characters of text\n",
      "pseudocicero had 1 pieces of work with a total of 12256 characters of text\n",
      "pseudoquintilian had 1 pieces of work with a total of 475491 characters of text\n",
      "psplato had 1 pieces of work with a total of 8802 characters of text\n",
      "pulchracomis had 1 pieces of work with a total of 217 characters of text\n",
      "qcicero had 1 pieces of work with a total of 28874 characters of text\n",
      "quintilian had 12 pieces of work with a total of 1183641 characters of text\n",
      "quum had 1 pieces of work with a total of 2281 characters of text\n",
      "raoul had 1 pieces of work with a total of 268357 characters of text\n",
      "regula had 1 pieces of work with a total of 40185 characters of text\n",
      "reposianus had 1 pieces of work with a total of 8568 characters of text\n",
      "resgestae had 1 pieces of work with a total of 19561 characters of text\n",
      "rhetores had 1 pieces of work with a total of 678 characters of text\n",
      "richerus had 1 pieces of work with a total of 101221 characters of text\n",
      "rimbaud had 1 pieces of work with a total of 2988 characters of text\n",
      "ruaeus had 1 pieces of work with a total of 17523 characters of text\n",
      "rumor had 1 pieces of work with a total of 943 characters of text\n",
      "rutilius had 1 pieces of work with a total of 29644 characters of text\n",
      "rutiliuslupus had 1 pieces of work with a total of 31477 characters of text\n",
      "sabinus had 1 pieces of work with a total of 4623 characters of text\n",
      "sall had 1 pieces of work with a total of 150818 characters of text\n",
      "sallust had 3 pieces of work with a total of 254194 characters of text\n",
      "sannazaro had 1 pieces of work with a total of 65699 characters of text\n",
      "scaliger had 1 pieces of work with a total of 294 characters of text\n",
      "scbaccanalibus had 1 pieces of work with a total of 4922 characters of text\n",
      "scottus had 1 pieces of work with a total of 1589 characters of text\n",
      "scriptoreshistoriaeaugustae had 4 pieces of work with a total of 527723 characters of text\n",
      "sedulius had 1 pieces of work with a total of 14042 characters of text\n",
      "sen had 1 pieces of work with a total of 53425 characters of text\n",
      "seneca had 42 pieces of work with a total of 2155204 characters of text\n",
      "senecatheelder had 8 pieces of work with a total of 666264 characters of text\n",
      "septsap had 1 pieces of work with a total of 49331 characters of text\n",
      "serviushonoratus had 4 pieces of work with a total of 355299 characters of text\n",
      "sha had 1 pieces of work with a total of 19068 characters of text\n",
      "sicmeafata had 1 pieces of work with a total of 798 characters of text\n",
      "sidonius had 1 pieces of work with a total of 42650 characters of text\n",
      "sigebert had 1 pieces of work with a total of 10679 characters of text\n",
      "silius had 1 pieces of work with a total of 30850 characters of text\n",
      "siliusitalicus had 17 pieces of work with a total of 538363 characters of text\n",
      "simedignetur had 1 pieces of work with a total of 308 characters of text\n",
      "smarius had 1 pieces of work with a total of 6792 characters of text\n",
      "solet had 1 pieces of work with a total of 11763 characters of text\n",
      "solinus had 1 pieces of work with a total of 241481 characters of text\n",
      "spinoza had 1 pieces of work with a total of 117778 characters of text\n",
      "statius had 18 pieces of work with a total of 656190 characters of text\n",
      "suetonius had 12 pieces of work with a total of 518934 characters of text\n",
      "sulpicia had 1 pieces of work with a total of 1697 characters of text\n",
      "sulpiciusseveruschron had 1 pieces of work with a total of 92885 characters of text\n",
      "sulpiciusseverusmartin had 1 pieces of work with a total of 48368 characters of text\n",
      "suscipeflos had 1 pieces of work with a total of 417 characters of text\n",
      "syrus had 1 pieces of work with a total of 56263 characters of text\n",
      "tacitus had 20 pieces of work with a total of 1204956 characters of text\n",
      "tempusest had 1 pieces of work with a total of 1210 characters of text\n",
      "ter had 1 pieces of work with a total of 61820 characters of text\n",
      "terence had 6 pieces of work with a total of 310741 characters of text\n",
      "terraiam had 1 pieces of work with a total of 1107 characters of text\n",
      "tertullian had 2 pieces of work with a total of 186130 characters of text\n",
      "testamentum had 1 pieces of work with a total of 2192 characters of text\n",
      "tevigilans had 1 pieces of work with a total of 351 characters of text\n",
      "theganus had 1 pieces of work with a total of 45690 characters of text\n",
      "theodolus had 1 pieces of work with a total of 16262 characters of text\n",
      "theodosius had 1 pieces of work with a total of 143782 characters of text\n",
      "theophanes had 1 pieces of work with a total of 1930 characters of text\n",
      "thesauro had 1 pieces of work with a total of 12371 characters of text\n",
      "thomasedessa had 1 pieces of work with a total of 73511 characters of text\n",
      "tibullus had 1 pieces of work with a total of 80686 characters of text\n",
      "tunger had 1 pieces of work with a total of 89239 characters of text\n",
      "valeriusflaccus had 8 pieces of work with a total of 278759 characters of text\n",
      "valeriusmaximus had 9 pieces of work with a total of 586001 characters of text\n",
      "valesianus had 1 pieces of work with a total of 120 characters of text\n",
      "valmax had 1 pieces of work with a total of 68958 characters of text\n",
      "varro had 1 pieces of work with a total of 33190 characters of text\n",
      "vegetius had 1 pieces of work with a total of 72149 characters of text\n",
      "vegius had 1 pieces of work with a total of 29868 characters of text\n",
      "vell had 1 pieces of work with a total of 167143 characters of text\n",
      "venantius had 1 pieces of work with a total of 5002 characters of text\n",
      "vergil had 17 pieces of work with a total of 579350 characters of text\n",
      "vicentius had 1 pieces of work with a total of 121964 characters of text\n",
      "vico had 1 pieces of work with a total of 21838 characters of text\n",
      "victor had 1 pieces of work with a total of 69412 characters of text\n",
      "vida had 1 pieces of work with a total of 30105 characters of text\n",
      "vitacaroli had 1 pieces of work with a total of 104331 characters of text\n",
      "vitruvius had 10 pieces of work with a total of 421054 characters of text\n",
      "volovirum had 1 pieces of work with a total of 1071 characters of text\n",
      "voragine had 1 pieces of work with a total of 3830 characters of text\n",
      "waardenburg had 1 pieces of work with a total of 3553 characters of text\n",
      "waltarius had 1 pieces of work with a total of 18263 characters of text\n",
      "walter had 1 pieces of work with a total of 2305 characters of text\n",
      "walton had 1 pieces of work with a total of 26036 characters of text\n",
      "williamapulia had 1 pieces of work with a total of 123908 characters of text\n",
      "williamtyre had 1 pieces of work with a total of 87915 characters of text\n",
      "withof had 1 pieces of work with a total of 7151 characters of text\n",
      "wmconchesdogma had 1 pieces of work with a total of 91687 characters of text\n",
      "wmconchesphil had 1 pieces of work with a total of 39080 characters of text\n",
      "xanten had 1 pieces of work with a total of 49919 characters of text\n",
      "xylander had 1 pieces of work with a total of 106561 characters of text\n",
      "zonaras had 1 pieces of work with a total of 76548 characters of text\n"
     ]
    }
   ],
   "source": [
    "CI = dataExp.CorpusInterface(corpus_name=\"text_corpus.pickle\", shouldTokenize = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbaf2dc-34b9-459e-95b5-9fa98ee74f80",
   "metadata": {},
   "source": [
    "Now that we've loaded in the Corpus Interface, let's retrieve all of the available text, find all the characters that occur in the text, which will be our vocabulary as this a character level transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93c66138-8acf-4c77-a93f-ced127ff0097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T15:17:43.381792Z",
     "iopub.status.busy": "2023-03-18T15:17:43.380697Z",
     "iopub.status.idle": "2023-03-18T15:17:44.075397Z",
     "shell.execute_reply": "2023-03-18T15:17:44.074374Z",
     "shell.execute_reply.started": "2023-03-18T15:17:43.381758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 61345135\n",
      "\u0000 !\"#$%&'()*+,-./0123456789:;<=>?@[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n",
      "70\n",
      "gesta francorum viii gesta francorum liber viii [x\n"
     ]
    }
   ],
   "source": [
    "# load in all the text from my Corpus Interface\n",
    "text = CI.get_total_data().replace(\"\\t\",\"\")\n",
    "print(\"Total number of characters: {}\".format(len(text)))\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)\n",
    "print(text[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ea3ae-440e-4bc2-83f0-582a6f14da3d",
   "metadata": {},
   "source": [
    "We know want to build a character tokenization since we are using a character level language model. For the next one, it may be worth it to try and use tokens generated from LatinBERT or lat word2vec, etc.\n",
    "\n",
    "And then we can use Pytorch to encode all the text we loaded in from before. And we print out the encoded version of the text we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b99796-800e-49d3-be61-9467f3cb4b16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T14:57:43.591089Z",
     "iopub.status.busy": "2023-03-18T14:57:43.590194Z",
     "iopub.status.idle": "2023-03-18T14:58:11.507463Z",
     "shell.execute_reply": "2023-03-18T14:58:11.506821Z",
     "shell.execute_reply.started": "2023-03-18T14:57:43.591059Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v = W2VE(\"lat\")\n",
    "st = SentenceTokenizer()\n",
    "wt = WordTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90460fdd-4955-4cf3-99e8-b3bef24daae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T15:00:18.689337Z",
     "iopub.status.busy": "2023-03-18T15:00:18.688310Z",
     "iopub.status.idle": "2023-03-18T15:00:18.878620Z",
     "shell.execute_reply": "2023-03-18T15:00:18.878049Z",
     "shell.execute_reply.started": "2023-03-18T15:00:18.689305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555381\n",
      "555381\n"
     ]
    }
   ],
   "source": [
    "print(len(w2v.model))\n",
    "count = 0 \n",
    "with open (\"vocab/vocab.txt\", \"w+\") as f:\n",
    "    text = \"\"\n",
    "    for word in w2v.model.index_to_key:\n",
    "        text+=word+\"\\n\"\n",
    "        count+=1\n",
    "    f.write(text)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04359065-c20d-45c0-9236-c14a55472b9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T15:13:37.229850Z",
     "iopub.status.busy": "2023-03-18T15:13:37.228849Z",
     "iopub.status.idle": "2023-03-18T15:13:37.625444Z",
     "shell.execute_reply": "2023-03-18T15:13:37.624774Z",
     "shell.execute_reply.started": "2023-03-18T15:13:37.229820Z"
    }
   },
   "outputs": [],
   "source": [
    "stoi = {}\n",
    "itos = {}\n",
    "with open(\"vocab/vocab.txt\", \"r\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    del lines[len(lines)-1]\n",
    "    for idx in range(len(lines)):\n",
    "        stoi[lines[idx]] = idx\n",
    "        itos[idx] = lines[idx]\n",
    "\n",
    "encode = lambda s: [stoi[word] for word in wt.tokenize(s) if word in stoi]\n",
    "decode = lambda l: [' '.join([itos[i] for i in l])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cd0b910-dc0b-405e-a28d-c18e24df436f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T15:35:37.916057Z",
     "iopub.status.busy": "2023-03-18T15:35:37.915321Z",
     "iopub.status.idle": "2023-03-18T15:35:37.922696Z",
     "shell.execute_reply": "2023-03-18T15:35:37.921869Z",
     "shell.execute_reply.started": "2023-03-18T15:35:37.916024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 583, 13723]\n",
      "['de bello gallico']\n",
      "gesta francorum viii gesta francorum liber viii [x\n",
      "torch.Size([17]) torch.int64\n",
      "tensor([ 2494,  2109,  1084,  2494,  2109,   466,  1084,    46,  3543,    41,\n",
      "        26363,    90, 40248,  3328, 57085,     3, 23419])\n"
     ]
    }
   ],
   "source": [
    "#encode = lambda s: [w2v.get_word_vector(word) for word in wt.tokenize(s)]\n",
    "#decode = lambda l: [w2v.get_sims(v)[0][0] for v in l]\n",
    "\n",
    "# Recall that I'm using all lower case for input (could also be all uppercase, was choosen arbitraily)\n",
    "print(encode(\"De Bello Gallico\".lower()))\n",
    "print(decode(encode(\"De Bello Gallico\".lower())))\n",
    "print(text[:50])\n",
    "data = torch.tensor(encode(text[:100]), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "699bf767-030e-46bf-8567-96391cd8cc81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T15:17:12.939244Z",
     "iopub.status.busy": "2023-03-18T15:17:12.938093Z",
     "iopub.status.idle": "2023-03-18T15:17:12.943484Z",
     "shell.execute_reply": "2023-03-18T15:17:12.942966Z",
     "shell.execute_reply.started": "2023-03-18T15:17:12.939211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([581996]) torch.int64\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, data.dtype)\n",
    "print(data[:100]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd31d7a-86d4-4a8d-98ad-f85afe535cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:21:19.419796Z",
     "iopub.status.busy": "2023-03-08T21:21:19.419383Z",
     "iopub.status.idle": "2023-03-08T21:21:24.299578Z",
     "shell.execute_reply": "2023-03-08T21:21:24.298623Z",
     "shell.execute_reply.started": "2023-03-08T21:21:19.419762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 44, 1, 41, 44, 51, 51, 54, 1, 46, 40, 51, 51, 48, 42, 54]\n",
      "de bello gallico\n",
      "torch.Size([61344458]) torch.int64\n",
      "tensor([42, 15,  1, 40, 58, 48, 53, 48, 54,  1, 42, 15,  1, 40, 53, 59, 48, 58,\n",
      "        59, 48, 54,  1, 42, 54, 53, 58, 60, 51, 48, 41, 60, 58,  1, 53, 54, 53,\n",
      "        60, 58,  1, 59, 48, 41, 44, 57, 48, 54,  1, 40, 53, 53])\n"
     ]
    }
   ],
   "source": [
    "# We just create a mapping between our character vocabulary\n",
    "# and their corresponding integer value, and define lambda funcs to do this mapping for us\n",
    "#stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "#itos = { i:ch for i,ch in enumerate(chars)}\n",
    "#encode = lambda s: [stoi[c] for c in s] \n",
    "#decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "# Recall that I'm using all lower case for input (could also be all uppercase, was choosen arbitraily)\n",
    "print(encode(\"De Bello Gallico\".lower()))\n",
    "print(decode(encode(\"De Bello Gallico\".lower())))\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:50]) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56133dea-be32-4b1a-a55f-f25e27a1f4a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:21:30.837178Z",
     "iopub.status.busy": "2023-03-08T21:21:30.836345Z",
     "iopub.status.idle": "2023-03-08T21:21:30.841498Z",
     "shell.execute_reply": "2023-03-08T21:21:30.840394Z",
     "shell.execute_reply.started": "2023-03-08T21:21:30.837124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create a train/val split\n",
    "n = int(.8*len(data)) \n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648df7a-6059-4fce-ad83-e327b0984880",
   "metadata": {},
   "source": [
    "## Batches of context blocks\n",
    "We define a block/context size and load in the data for each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a90495f-7a37-4301-8887-f95f3a96e115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:21:52.754936Z",
     "iopub.status.busy": "2023-03-08T21:21:52.754067Z",
     "iopub.status.idle": "2023-03-08T21:21:52.764149Z",
     "shell.execute_reply": "2023-03-08T21:21:52.763578Z",
     "shell.execute_reply.started": "2023-03-08T21:21:52.754905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[44, 57, 60, 53, 59, 15,  1, 44],\n",
      "        [52,  1, 48, 51, 51, 48, 58,  1],\n",
      "        [48, 53, 59, 44, 46, 57, 40,  1],\n",
      "        [48, 53, 48, 58,  1, 40, 43,  1]])\n",
      "Targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[57, 60, 53, 59, 15,  1, 44, 59],\n",
      "        [ 1, 48, 51, 51, 48, 58,  1, 54],\n",
      "        [53, 59, 44, 46, 57, 40,  1, 57],\n",
      "        [53, 48, 58,  1, 40, 43,  1, 51]])\n",
      "--------------------\n",
      "When input is [44] the target is 57\n",
      "When input is [44, 57] the target is 60\n",
      "When input is [44, 57, 60] the target is 53\n",
      "When input is [44, 57, 60, 53] the target is 59\n",
      "When input is [44, 57, 60, 53, 59] the target is 15\n",
      "When input is [44, 57, 60, 53, 59, 15] the target is 1\n",
      "When input is [44, 57, 60, 53, 59, 15, 1] the target is 44\n",
      "When input is [44, 57, 60, 53, 59, 15, 1, 44] the target is 59\n",
      "When input is [52] the target is 1\n",
      "When input is [52, 1] the target is 48\n",
      "When input is [52, 1, 48] the target is 51\n",
      "When input is [52, 1, 48, 51] the target is 51\n",
      "When input is [52, 1, 48, 51, 51] the target is 48\n",
      "When input is [52, 1, 48, 51, 51, 48] the target is 58\n",
      "When input is [52, 1, 48, 51, 51, 48, 58] the target is 1\n",
      "When input is [52, 1, 48, 51, 51, 48, 58, 1] the target is 54\n",
      "When input is [48] the target is 53\n",
      "When input is [48, 53] the target is 59\n",
      "When input is [48, 53, 59] the target is 44\n",
      "When input is [48, 53, 59, 44] the target is 46\n",
      "When input is [48, 53, 59, 44, 46] the target is 57\n",
      "When input is [48, 53, 59, 44, 46, 57] the target is 40\n",
      "When input is [48, 53, 59, 44, 46, 57, 40] the target is 1\n",
      "When input is [48, 53, 59, 44, 46, 57, 40, 1] the target is 57\n",
      "When input is [48] the target is 53\n",
      "When input is [48, 53] the target is 48\n",
      "When input is [48, 53, 48] the target is 58\n",
      "When input is [48, 53, 48, 58] the target is 1\n",
      "When input is [48, 53, 48, 58, 1] the target is 40\n",
      "When input is [48, 53, 48, 58, 1, 40] the target is 43\n",
      "When input is [48, 53, 48, 58, 1, 40, 43] the target is 1\n",
      "When input is [48, 53, 48, 58, 1, 40, 43, 1] the target is 51\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "torch.manual_seed(42)\n",
    "context_size = 8 # size of the context\n",
    "batch_size = 4 # independent batches trained in parallel\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - context_size, (batch_size,))\n",
    "    # create a batch by context size tensor of the data\n",
    "    x = torch.stack([data[i:i+context_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"Inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"Targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('-'*20)\n",
    "for b in range(batch_size): \n",
    "    for t in range(context_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"When input is {context.tolist()} the target is {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d846b-0f0c-4284-8786-70bd4ef96e44",
   "metadata": {},
   "source": [
    "## Bigram model\n",
    "A simple bigram model that will function as a baseline for our subsequent transformer in terms of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aba1398-ffb1-4840-a2e1-5731eb269200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:22:01.340188Z",
     "iopub.status.busy": "2023-03-08T21:22:01.339006Z",
     "iopub.status.idle": "2023-03-08T21:22:01.365438Z",
     "shell.execute_reply": "2023-03-08T21:22:01.364625Z",
     "shell.execute_reply.started": "2023-03-08T21:22:01.340152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 70])\n",
      "tensor(5.0427, grad_fn=<NllLossBackward0>)\n",
      "\u0000:trq/z!./@*r_>$%q><yng+6;!vnhnt\"^l;ww$3vp__&9<vb\\/|hw .*4mn]p[p_j|8&wo~#pt-$60\\s\\14\\r'sfq_[/]h48l#6;\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class BigramLM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # tokens correspond to a frequency lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        # idx and targets are both (batch, time) tensors of integers\n",
    "        logits = self.token_embedding_table(idx) # (batch, time, channel) where chanel is vocab_size\n",
    "        \n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            \"\"\" \n",
    "            loss function -negative log likelihood\n",
    "            but cross_entropy wants (B*T, C), this effectively\n",
    "            means we're making our 3d matrix into a 2d one where the next batch\n",
    "            follows the prior one in time\n",
    "            \"\"\"\n",
    "            batch, time, channel = logits.shape\n",
    "\n",
    "            logits = logits.view(batch*time, channel)\n",
    "            targets = targets.view(batch*time)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \"\"\"\n",
    "        Right now, history is not being used so passing in all the history is silly in self(idx)\n",
    "        since it's a bigram model it only needs the prior character, but this is a very general and\n",
    "        reusable function for later\n",
    "        \"\"\"\n",
    "        #idx is (batch, time) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get predictions\n",
    "            logits, loss = self(idx)\n",
    "            # most recent time step\n",
    "            logits = logits[:, -1, :] # (batch, channel)\n",
    "            # softmax for probability\n",
    "            probs = F.softmax(logits, dim=-1) #probabilities for each batch by vocab size\n",
    "            # sample from the probability dist\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (Batch, 1)\n",
    "            # append the newly sampled prediction to the sequence \n",
    "            idx = torch.cat((idx, idx_next), dim=1) # batch, timestep+1\n",
    "        return idx\n",
    "m = BigramLM(vocab_size)\n",
    "out, loss = m(xb, yb)\n",
    "print(out.shape)\n",
    "print(loss)\n",
    "# start a prediction of one batch size starting with ' ' and then generate for 100 tokens\n",
    "# 0th row for the only batch dimension \n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long),max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de466c-0b5d-4574-9dcf-6f6365c0e004",
   "metadata": {},
   "source": [
    "Now let's train the above model, just rerunning the optimization below until satisfied -- not a very sophisticated approach, but we're also not particularly bothered by the bigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78cc2372-d923-466c-8a4c-5ef6284fec46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:02:05.419817Z",
     "iopub.status.busy": "2023-03-08T21:02:05.418831Z",
     "iopub.status.idle": "2023-03-08T21:02:05.423915Z",
     "shell.execute_reply": "2023-03-08T21:02:05.423135Z",
     "shell.execute_reply.started": "2023-03-08T21:02:05.419786Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2150a517-8dcf-44bc-8410-978943b4ddec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:05:03.024358Z",
     "iopub.status.busy": "2023-03-08T21:05:03.023979Z",
     "iopub.status.idle": "2023-03-08T21:05:35.498729Z",
     "shell.execute_reply": "2023-03-08T21:05:35.497060Z",
     "shell.execute_reply.started": "2023-03-08T21:05:03.024279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.542701244354248\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    # sample a batch\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb,yb)\n",
    "    # zero out gradients from prior step\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    # getting gradients for all parameters\n",
    "    loss.backward()\n",
    "    # update parameters from gradients\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee1b7587-5612-46ca-add2-35764a4ccb23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:06:31.354997Z",
     "iopub.status.busy": "2023-03-08T21:06:31.354281Z",
     "iopub.status.idle": "2023-03-08T21:06:31.399947Z",
     "shell.execute_reply": "2023-03-08T21:06:31.399033Z",
     "shell.execute_reply.started": "2023-03-08T21:06:31.354969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000z_c iope quist qusomia iquat nun cetere e, c qusueoninor, derorm qumiss \". heho raemelt, cc qum pr aviriatubocmi cutqumut pprit quddeae senosintefilultanclirbiegen inue caenusiunatonereniqulins coss. iope kes cla qum frm enuct simiae; fit utuerukworeun fum pue  oet  deno cisu nus qusse lactor. ata, tt at, osterrat, cas cusiatin vus: mius fe eruni isibit qum qusaciciausso inuins,  ereiabe ponarus q\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long),max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ecab3-9689-490c-907a-d72c3a5935c4",
   "metadata": {},
   "source": [
    "The above, albeit giberish, is clearly an immense improvement upon the initial prediction without optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e2700-e2e5-4825-8696-cb535df22977",
   "metadata": {},
   "source": [
    "## Self Attention\n",
    "\n",
    "### first a simple mathematical trick in self-attention\n",
    "The following is highly ineffecient, but can be sped up via matrix multiplication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eadb1372-e94e-4857-9a94-eedc46347bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:23:28.909459Z",
     "iopub.status.busy": "2023-03-08T21:23:28.908215Z",
     "iopub.status.idle": "2023-03-08T21:23:28.918649Z",
     "shell.execute_reply": "2023-03-08T21:23:28.917626Z",
     "shell.execute_reply.started": "2023-03-08T21:23:28.909423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9269,  1.4873],\n",
      "        [ 0.9007, -2.1055],\n",
      "        [ 0.6784, -1.2345],\n",
      "        [-0.0431, -1.6047],\n",
      "        [-0.7521,  1.6487],\n",
      "        [-0.3925, -1.4036],\n",
      "        [-0.7279, -0.5594],\n",
      "        [-0.7688,  0.7624]])\n",
      "tensor([[ 1.9269,  1.4873],\n",
      "        [ 1.4138, -0.3091],\n",
      "        [ 1.1687, -0.6176],\n",
      "        [ 0.8657, -0.8644],\n",
      "        [ 0.5422, -0.3617],\n",
      "        [ 0.3864, -0.5354],\n",
      "        [ 0.2272, -0.5388],\n",
      "        [ 0.1027, -0.3762]])\n"
     ]
    }
   ],
   "source": [
    "# toy example for self-attention \n",
    "torch.manual_seed(42)\n",
    "batch, time, channel = 4,8,2 \n",
    "x = torch.randn(batch, time, channel)\n",
    "x.shape\n",
    "\n",
    "# we want x[b,t] = mean_{i<=t} x[b,i]\n",
    "\n",
    "xbow = torch.zeros((batch, time, channel))\n",
    "for b in range(batch):\n",
    "    for t in range(time):\n",
    "        xprev = x[b, :t+1] # (t, channel)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "print(x[0])\n",
    "print(xbow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ffac2-830e-471c-b963-cffd13125b07",
   "metadata": {},
   "source": [
    "The 'mathematical trick' is what I presumed would be the approach when given the problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8813f02-f7a5-4099-bec7-dfb3021583e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:28:59.271191Z",
     "iopub.status.busy": "2023-03-08T21:28:59.270401Z",
     "iopub.status.idle": "2023-03-08T21:28:59.282341Z",
     "shell.execute_reply": "2023-03-08T21:28:59.281546Z",
     "shell.execute_reply.started": "2023-03-08T21:28:59.271159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10, (3,2)).float()\n",
    "c = a @ b\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"--\\nc=\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0bf4d5d-754a-465c-888c-64a126fcb0a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:33:00.914734Z",
     "iopub.status.busy": "2023-03-08T21:33:00.914391Z",
     "iopub.status.idle": "2023-03-08T21:33:00.923475Z",
     "shell.execute_reply": "2023-03-08T21:33:00.922682Z",
     "shell.execute_reply.started": "2023-03-08T21:33:00.914710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9269,  1.4873],\n",
      "        [ 1.4138, -0.3091],\n",
      "        [ 1.1687, -0.6176],\n",
      "        [ 0.8657, -0.8644],\n",
      "        [ 0.5422, -0.3617],\n",
      "        [ 0.3864, -0.5354],\n",
      "        [ 0.2272, -0.5388],\n",
      "        [ 0.1027, -0.3762]])\n",
      "tensor([[ 1.9269,  1.4873],\n",
      "        [ 1.4138, -0.3091],\n",
      "        [ 1.1687, -0.6176],\n",
      "        [ 0.8657, -0.8644],\n",
      "        [ 0.5422, -0.3617],\n",
      "        [ 0.3864, -0.5354],\n",
      "        [ 0.2272, -0.5388],\n",
      "        [ 0.1027, -0.3762]])\n"
     ]
    }
   ],
   "source": [
    "# doing this now for the example above we can do the following\n",
    "\n",
    "weights = torch.tril(torch.ones(time, time))\n",
    "weights = weights / weights.sum(1, keepdim=True)\n",
    "# weights is a \n",
    "# and b is now x\n",
    "\n",
    "xbow2 = weights @ x # (time, time) @ (batch, time, channel) -> (batch, time, time) @ (batch, time, channel) -> (batch, time, channel)\n",
    "print(xbow[0])\n",
    "print(xbow2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "882ce108-2ae8-4e7a-a1b7-0aa542d26c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T21:39:52.616290Z",
     "iopub.status.busy": "2023-03-08T21:39:52.615338Z",
     "iopub.status.idle": "2023-03-08T21:39:52.624841Z",
     "shell.execute_reply": "2023-03-08T21:39:52.624073Z",
     "shell.execute_reply.started": "2023-03-08T21:39:52.616262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but now with softamx\n",
    "tril = torch.tril(torch.ones(time, time))\n",
    "weights = torch.zeros((time,time))\n",
    "weights = weights.masked_fill(tril==0, float('-inf'))\n",
    "# softmax also normalizes it in the same way we do \n",
    "# weights = weights/weights.sum(1, keepdim= True) as above\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "xbow3 = weights @ x\n",
    "torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a75e4440-3770-4eb5-9147-73639ece0747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T22:05:18.476283Z",
     "iopub.status.busy": "2023-03-08T22:05:18.475942Z",
     "iopub.status.idle": "2023-03-08T22:05:18.498177Z",
     "shell.execute_reply": "2023-03-08T22:05:18.497400Z",
     "shell.execute_reply.started": "2023-03-08T22:05:18.476259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1905, 0.8095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3742, 0.0568, 0.5690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1288, 0.3380, 0.1376, 0.3956, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4311, 0.0841, 0.0582, 0.3049, 0.1217, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0537, 0.3205, 0.0694, 0.2404, 0.2568, 0.0592, 0.0000, 0.0000],\n",
      "        [0.3396, 0.0149, 0.5165, 0.0180, 0.0658, 0.0080, 0.0373, 0.0000],\n",
      "        [0.0165, 0.0375, 0.0144, 0.1120, 0.0332, 0.4069, 0.3136, 0.0660]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# version 4, self attention\n",
    "torch.manual_seed(42)\n",
    "batch, time, channel = 4, 8, 32\n",
    "x = torch.randn(batch,time, channel)\n",
    "\n",
    "# single head of self attention \n",
    "# head size is hyper-parameter\n",
    "head_size = 16\n",
    "key = nn.Linear(channel, head_size, bias = False)\n",
    "query = nn.Linear(channel, head_size, bias = False)\n",
    "value = nn.Linear(channel, head_size, bias = False)\n",
    "\n",
    "k = key(x) # (batch, time, head_size)\n",
    "q = query(x) # (batch, time, head_size)\n",
    "\n",
    "# -2 and -1 because we don't want to transpose the batch)\n",
    "weights = q @ k.transpose(-2, -1) # (batch, time, head_size) @   (batch, time, head_size) ----> (batch, time, time) the affiniites\n",
    "\n",
    "tril = torch.tril(torch.ones(time, time))\n",
    "# don't want to interact with subsequent time step tokens\n",
    "weights = weights.masked_fill(tril==0, float('-inf'))\n",
    "# make the probability nicely distributed\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "#out = weights @ x\n",
    "v = value(x)\n",
    "out = weights @ v \n",
    "\n",
    "print(out.shape)\n",
    "print(tril)\n",
    "print(weights[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
